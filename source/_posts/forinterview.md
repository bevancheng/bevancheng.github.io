---
title: forinterview
date: 2022-06-04 20:27:37
tag: hello
---
## 系统

### 操作系统复习（突击）

#### 临界区的概念

各个进程中对临界资源（互斥资源/共享变量，一次只能给一个进程使用）进行操作的程序片段。

> 同步和互斥
>
> 同步：多个进程因为合作而使得进程的执行有一定的先后顺序。比如某个进程需要另一个进程提供的消息，获得消息之前进入==阻塞态==。
>
> 互斥：多个进程在同一时刻只有一个进程能进入临界区

>并发、并行、异步
>
>并发：同一时间段中同时有多个程序在运行，但其实再任一时刻，只有一个程序再CPU上运行，宏观上的并发是通过不断切换实现的。
>
>多线程：并发运行的一段代码，实现异步的手段
>
>并行（compared with 串行）：多CPU系统中，多个程序无论宏观还是微观上都是同时执行的
>
>异步（与同步相比）：同步时顺序执行，异步是在等待某个资源的时候继续做自己的事
<!--more-->
#### 进程有哪几种状态

![Process State](https://github.com/wolverinn/Waking-Up/raw/master/_v_images/20191202090217863_1873.png)



就绪状态：进程已获得除==处理机==以外的所需资源，等待分配处理机资源

运行状态：占用处理机资源运行，处于此状态的进程数<=cpu数

阻塞状态：进程等待某种条件，再条件满足之前无法执行

#### 进程调度策略

1.批处理系统：

> 先来先服务 first-come first-served (FCFS)
>
> 按照请求顺序进行调度。非抢占式，开销小、无饥饿问题，响应时间不确定
>
> 对短进程不利，对IO密集型进程不利

>最短作业优先 shortest job first (SJF)
>
>按估计运行时间最短的顺序进行调度，非抢占式，吞吐量高，开销可能较大，可能导致==饥饿问题==

> 最短剩余时间优先 shortest remaining time next （SRTN）
>
> 按剩余运行时间顺序进行调度。（SJF的抢占式版本）。吞吐量高，开销较大，提供好的响应时间

> 最高相应比优先 Highest Response Ratio Next (HRRN)
>
> 响应比 = 1+等待时间/处理时间。
>
> 同时考虑了等待时间和估计需要的执行时间，很好的平衡了长短进程。非抢占，吞吐量高，开销可能较大，响应时间好，无饥饿问题



2.交互式系统

有大量用户交互操作，在该系统中调度算法的目标是快速地进行响应。

> 时间片轮转 Round Robin



>优先级调度算法
>
>为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级

> 多级反馈队列调度算法
>
> 设置多个就绪队列1、2、3...，优先级递减，时间片递增。
>
> 对IO型进程有利，可能出现饥饿问题。

#### 优先级反转？解决？

高优先级的进程等待一个被低优先级进程占用的资源时，会出现优先级反转，即优先级较低的进程比优先级较高的进程先执行。如果中优先级将低优先级的进程抢占，此时低优先级进程无法正常进行并在后续释放被占用资源，导致高优任务被一直挂起，直到中优完成，低优进程才可以继续并在后续释放占用的资源，最后高优才执行。

解决：

优先级天花板（priority ceiling）：当任务申请某资源，把该任务优先级提升到可访问该资源的所有任务中的最高优先级，这个优先级称为该资源的优先级天花板。

优先级继承（priority inheritance）：A申请共享资源S，如果S正被C使用，比较AC发现C优先级小于自身优先级，则将C的优先级提升到自身的优先级，C释放S后，再恢复C的原优先级

#### 僵尸进程

子进程结束，其父进程并未等待它（调用wait or waitpid），则该子进程将成为一个僵尸进程。僵尸进程放弃了几乎所有内存空间，没有任何可执行代码，也不能被调度，仅仅在进程表中保留一个位置，记载该进程的进程ID、终止状态以及资源利用信息（CPU时间、内存使用量）供父进程收集。这个僵尸进程可能会一直留在系统中直到系统重启。

危害：占用进程号，系统能提供的进程号是有限的；占用内存。

如何不产生僵尸进程：

>该进程的父进程先结束了。每个进程结束时，系统都会扫描是否存在子进程，若有则用Init进程接管，成为该进程的父进程，并调用wait等待其结束

>父进程调用wait或者waitpid等待子进程结束（隔一段时间查询子进程是否结束）。
>
>wait会使父进程暂停，直到它的一个子进程结束为止。
>
>waitpid则可加入WNOHANG（wait-no-hang）选项，如果没有发现结束的子进程，则会立刻返回，不会将调用waitpid的进程阻塞。同时waitpid可以选择：等待任一子进程（wait），等待指定pid子进程，等待同一进程组下的任一子进程，等待组ID等于pid的任一子进程

>子进程结束，系统产生SIGCHLD（signal-child）信号，可注册一个信号处理函数，在该函数中调用waitpid，等待所有结束的子进程（循环调用waitpid将所有结束的子进程回收）

>signal(SIGCLD,SIG_IGN) （signal-ignore）通知内核，表示忽略SSIGCLD信号，那么子进程结束后，内核会进行回收。



#### 孤儿进程

父进程先结束，子进程还在运行，则成为孤儿。会被Init进程接管（进程ID等于1），结束时由Init完成状态收集工作。

### 线程同步

> 为什么线程同步：线程有时回合其他线程共享一些资源，比如内存、数据库等。当多个线程同时读写同一份共享资源时，可能会发生冲突。因此需要线程同步，多个线程按顺序访问资源

互斥量 Mutex：互斥量是内核对象，只有拥有互斥对象的线程才有访问互斥资源的权限。

因为互斥对象只有一个，所以可以保证互斥资源不会被多个线程同时访问；当拥有互斥对象的线程处理完任务后必须交出互斥对象，以便其他线程访问该资源。



信号量 Semaphore：信号量是内核对象， 允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。信号量对象保存了**最大资源计数**和**当前可用资源计数**，每增加一个线程对共享资源的访问，当前可用资源计数减一，只要当前可用资源计数大于0，就可发出信号量信号，如果0，将线程放入一个队列中等待。线程处理完共享资源后，离开的同时通过ReleaseSemaphore函数将当前可用资源加1.如果信号量取值为0or1，那么信号量就成了互斥量。



事件 Event：允许一个线程在处理完一个任务后，主动唤醒另一个线程执行任务。

分为手动重置事件和自动重置时间。

手动重置时间设置为激发状态后，会唤醒所有等待的线程，并一直保持为激发状态，直到程序重新把它设置为未激发状态。

自动重置时间被设置为激发状态后，唤醒一个等待中的线程，并自动恢复为未激发状态。



临界区 Critical Section：任意时刻只允许一个线程对临界资源进行访问。拥有临界区对象的线程可以访问该临界资源，其他试图访问该资源的线程会被挂起，直到临界区对象被释放（不懂）



Difference between 互斥量和临界区

互斥量可被命名，可用于不同进程之间的同步；临界区只能用于同一进程中线程的同步。创建互斥量需要资源更多，因此临界区的优势是速度快，节省资源。



### 协程（不懂）

协程是一种用户态的轻量级线程，其调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来时，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文切换非常快

与线程的比较：

1.一个线程可拥有多个协程，一个进程也可单独拥有多个协程，这样python中则能使用多核CPU

2.线程进程都是同步机制，而协程是异步

3.协程能保留上一次调用时的状态，每次过程重入时，就相当于进入上一次调用的状态。



### 进程的异常控制流：陷阱、中断、异常和信号

陷阱时有意造成的”异常“，是执行一条指令的结果。陷阱是同步的。陷阱的主要作用是实现系统调用。如进程执行syscall n指令向内核请求服务。进程执行这条命令时，会中断当前控制流，陷入内核态，执行syscall。内核处理程序在执行结束后，将结果返回给进程，同时退回到用户态。进程此时继续吓一跳指令。

中断由处理器外部的硬件产生，不是指令的结果，无法预测。中断独立于当前执行的程序，因此中断是异步事件。中断包括I/O设备发出的I/O中断、各种定时器引起的时钟中断、调试程序中的断点引起的调试中断。

异常是一种错误情况，是执行当前指令的结果，可能会被错误处理程序修正，也可能直接终止应用程序。异常是同步的。特指因执行当前指令而产生的错误情况，如除法异常、缺页异常。

信号是更高层的软件形式的异常，同样中断进程的控制流，可以由进程进行处理。信号用来通知进程发生了某种系统事件。

### IO多路复用？实现？

IO Multiplexing，指单个进程/线程可以同时处理多个IO请求。

实现：用户将想要监视的文件描述符（File Descriptor）添加到select/poll/epoll函数中，由内核监视，函数阻塞。当有文件描述符就绪（读就绪or写就绪），或者超时（设置timeout），函数返回，该进程可以进行读写操作。

select/poll/epoll：文件描述符放入一个集合中，当调用select，将这个集合由用户空间拷贝至内核空间（缺点1：每次复制开销大），由内核根据就绪状态修改该集合的内容。（2：集合有大小限制，32位机1024，64位2048）；采用水平触发机制。select返回后，通过遍历这个集合，找到就绪的FD，（3，轮询的方式效率较低），当FD数量增加，，效率会线性下降。

poll：与select的区别在于FD的储存方式不同，poll采用链表储存，无最大储存数量限制。

epoll：内核和用户空间共享内存，避免不断复制的问题；支持的同时连接数上限很高（1G内存支持10w左右连接数）；fd就绪，采用回调机制，避免轮询（回调函数将就绪的fd添加到一个链表，执行epoll_wait时返回这个链表）；支持水平触发和边缘触发，

summary：

1.一个进程/线程能打开的最大连接数

2.fd的传递方式（复制）

3.ET和LT

4.查询就绪fd时的效率（轮询）



连接数较多，很多不活跃连接：epoll效率高很多

连接数较少，且都很活跃，由于epoll需要很多回调，因此性能可能低



文件描述符

形式上是个非负整数。实际上是个索引值，指向内核为每个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件，内核向进程返回一个fd

内核通过fd访问文件，fd指向一个文件。



### 水平触发 边缘触发

level trigger：只要一个fd就绪，触发通知，如果用户程序没有一次性把数据读写完，下次还会通知；

edge trigger：fd从未就绪到就绪时通知一次，之后不会再通知，直到再次由未就绪到就绪（buffer由不可读写变为可读写）

difference：ET效率更高，减少了被重复触发的次数，函数不会返回大量用户程序可能不需要的fd

why ET一定要用非阻塞IO（non-block IO）：避免由于一个fd的阻塞读/阻塞写操作让处理其他fd的任务出现饥饿状态。？？？

### IO模型

同步阻塞IO（blocking IO）：用户线程发起IO读/写操作之后，线程阻塞，直到可以开始处理数据；对CPU资源的利用率不够。

同步非阻塞IO（Non-blocking IO）：发起IO请求后可以立即返回，如果没有就绪的数据，需要不断发起IO请求直到数据就绪；不断重复请求消耗了大量CPU资源。

IO多路复用

异步IO（Asynchronous IO）：用户线程发出IO请求后，继续执行，由内核进行数据的读取并放在用户指定缓冲区，在IO完成后通知用户线程直接使用。

### 用户态 内核态

为了限制不同程序的访问能力，防止一些程序访问其他程序的内存数据，CPU划分了用户态和内核态两个权限等级。

用户态：受限地访问内存，不允许访问外围设备，没有占用CPU能力，CPU资源可以被其他程序获取

内核态：可访问内存所有数据及外围设备，也可进行程序切换



用户程序运行在用户态，有时需要进行一些内核态操作，如从硬盘或者键盘读数据，此时需要系统调用，使用陷阱指令，CPU切换到内核态，执行服务，再切换到用户态返回系统调用的结果。

为什么分用户态和内核态：

安全性：防止用户程序恶意或不小心破坏系统内存硬件资源

封装性；用户不需要实现底层代码

便于调度：多个程序等待键盘输入，此时需要进行调度，统一交给操作系统调度更方便

#### 切换用户态到内核态

系统调用：读取命令行输入。通过中断实现

用户程序发生异常：缺页异常

外围设备中断：

## 死锁

两个或多个并发进程中，每个进程持有某种资源而又等待其他进程释放它们现在保持着地资源，在未改变这种状态之前都不能向前推进，称这一组进程产生了死锁（deadlock）。

### 死锁产生的必要条件

互斥：一个资源一次只能被一个进程使用

占有并等待：一个进程至少占有一个资源，并等待另一个被其他进程占用地资源

非抢占：已经分配给一个进程的资源不能被强制性抢占，只能由进程完成任务后自愿释放

循环等待：若干进程之间形成头尾相接地环形等待资源关系，环路中每个进程都在等待下一个进程所占有的资源

### 死锁的处理方式

> 鸵鸟策略
>
> 直接忽略死锁。解决死锁的代价很高，不采取任务措施可以获得更高性能。发生死锁不会产生多大影响，或者发生死锁概率很低，可采用鸵鸟策略。

>死锁预防
>
>基本思想是破环四个必要条件
>
>破坏互斥：允许资源被多个进程访问。
>
>破坏占有并等待条件：
>
>​		资源预先分配策略：当一个进程开始运行前，必须一次性像系统申请它所需要的全部资源，否则不运行
>
>​		只允许进程在没有占用资源时才能申请资源（申请前先释放占用的资源）
>
>​		缺点：无法预知资源需要多少，同时会降低资源利用率，降低系统并发性
>
>破坏非抢占：允许进程抢占被其他进程占有的资源。会降低系统性能
>
>破坏循环等待：对所有资源统一编号，进程对资源的请求必须按照序号递增顺序提出，即只有占有了编号较小的资源才能申请编号较大的资源。避免占有大号资源的进程去申请小号资源。

> 死锁避免
>
> 动态监测资源分配状态，确保系统处于安全状态，只有安全状态才会进行资源分配。安全状态：即使所有进程同时申请需要的所有资源（最坏情况），也存在某种对进程的资源分配顺序，使得每个进程运行完毕。
>
> > 银行家算法

> 死锁解除
>
> 检测死锁：检测有向图是否存在环；或者使用类似死锁避免的检测算法
>
> 解除方法：
>
> ​	抢占：挂起某些进程，并抢占其资源。但应防止某些进程被长时间挂起而处于饥饿状态
>
> ​	回滚：让某些进程回退到足以解除死锁的地步，进程回退时自愿释放资源。系统需要保持进程的历史信息，设置还原点
>
> ​	杀死进程：强杀进程直到死锁解除，可按优先级进行。

### 分页和分段的区别

### 虚拟内存

每个程序拥有自己的地址空间，这个地址空间被分为大小相等的页，这些页被映射到物理内存，但不需要所有的页都在物理内存中，当程序引用到不在物理内存中的页时，由于操作系统将缺失的部分装入物理内存。对于程序来说，逻辑上似乎有很大的内存空间，只是实际上有一部分储存在磁盘上，因此叫虚拟内存。

优点是让程序可以获得更多的可用内存

实现方式：页表/多级页表，缺页中断，页面淘汰算法。。。

[🗂【面试题】技术面试题汇总 🔥 (imageslr.com)](https://imageslr.com/2020/07/08/tech-interview.html)

### 地址空间到物理内存的映射？

**内存管理单元**（MMU）管理者逻辑地址与物理地址的转换，页表（Page table）存储这页（逻辑地址）和页框（物理内存地址）的映射表，页表中包含有效位（在内存还是在磁盘）、访问位（是否被访问过）、修改位（内存中是否被修改过）、保护位（只读还是可读写）。逻辑地址：页号+页内地址（偏移）；每个进程一个页表，放在内存，页表起始地址在PCB/寄存器中。

### 页面置换算法

程序运行中，如果要访问的页不在内存，就会发生缺页中断从而将该页调入内存中。如果内存无空闲空间，系统必须从内存中调出一个页面到磁盘中来腾出空间。页面置换算法的主要目标是使页面置换频率最低（缺页率最低）。

> 最佳页面置换算法OPT（Optimal replacement algorithm）:置换后不需要或者最远的将来才需要的页面，理论上的算法，最优策略
>
> 先进先出FIFO：置换在内存中驻留时间最长的页面。缺点：可能将那些经常被访问的页面也被换出，从而使缺页率升高。
>
> 第二次机会算法SCR：按FIFO选择某一页面，若访问位为1，给第二次机会，并将访问位置置0
>
> 时钟算法Clock：SCR中需要将页面在链表中移动（第二次机会的时候要将这个页面从链表头移到链表尾），时钟算法使用环形链表，再使用一个指针指向最老的页面，避免移动页面的开销。（#####）
>
> 最近未使用算法NRU（Not Recently Used）：检查访问位R、修改位，优先置换R=M=0，其次是（R=0,M=1）；
>
> 最近最少使用算法LRU（Least Recently Used）：置换出未使用时间最长的一页；实现方式：维护时间戳，或者维护一个所有页面的链表。当一个页面被访问时，将这个页面移动到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。
>
> 最不经常使用算法NFU：置换出访问次数最少的页面

局部性原理：时间上：最近被访问的页在不久的将来还会被访问

空间上：内存中被访问的页周围的页也可能被访问



颠簸现象？

频繁的页调度行为。进程发生缺页中断时必须置换某一页，然而其他所有的页都在使用，置换一个页但又立刻再次需要这个页。因此会不断产生缺页中断，导致系统效率急剧下降，成为颠簸。内存颠簸的解决策略：

​	修改页面置换算法

​	降低同时运行的程序数量

​	终止该进程或增加物理内存容量

### 缓冲区溢出问题

what is 缓冲区溢出？

C使用运行时栈来存储过程信息。每个函数的信息存储在一个栈帧中，包括寄存器、局部变量、参数、返回地址等。C对数组引用不进行边界检查，因此对越界的数组元素的写操作会破坏存储在战中的状态信息，成为缓冲区溢出。缓冲区溢出会破坏程序运行，也可攻击，如用一个指向攻击代码的指针覆盖返回地址。

缓冲区溢出的防范方式

> 随机化：栈随机化（程序开始时在栈上分配一段随机大小的空间）和地址空间布局随机化（Address-Space Layout Randomization， ASLR，即每次运行时程序的不同部分、代码段、数据段、栈、堆都会被加载到内存空间的不同区域），不能保证安全
>
> 栈保护：在每个函数的栈帧的局部变量和栈状态之间储存一个随机产生的特殊值，成为金丝雀值（canary）。在恢复寄存器状态和函数返回之前，程序检测canary是否被改变，如果是，那么程序异常终止。
>
> 限制可执行代码区域：内存页的访问形式有3，可读可写可执行，只有编译器产生的部分代码所处的内存才是可执行的，其他页限制为只允许读和写

### 磁盘调度

过程：磁头（找对应盘面）；磁道（一个盘面上的同心圆环，寻道时间）；扇区（旋转时间）。为减少寻道时间的调度算法
FCFS

最短寻道时间优先

电梯算法：电梯总是保持一个方向运行，直到该方向没有请求为止，然乎改变运行方向。

## 网络

### OSI参考模型

上到下共7层

>应用层：应用层协议定义的是**应用进程间通信和交互**的规则，不同的网络应用需要不同的应用层协议
>
>表示层：把数据转换为能与**接收者**的系统格式兼容并适合传输的格式
>
>会话层：在数据传输中设置和维护电脑网络中两台电脑之间的通信连接
>
>传输层：向两台主机进程之间的通信提供**通用的**数据传输服务
>
>网络层：基于网络层地址（IP地址）进行不同网络系统间的路径选择
>
>数据链路层：在不可靠的物理介质上提供可靠的传输
>
>物理层：在局域网上透明地传输比特，尽可能屏蔽掉具体传输介质和物理设备的差异

### TCP/IP 参考模型

上到下分四层

>应用层：对应OSI中的应用层，为用户提供所需要的各种服务。定义的是应用进程间通信和交互的规则，不同网络应用需要不同的应用层协议。SMTP、HTTP、FTP
>
>传输层：对应OSI中的传输层，为应用端实体提供端到端、通用的通信功能，保证了数据包的顺序传送及数据的完整性。”通用的”指不同应用可以使用同一个运输层服务。TCP、UDP
>
>网络层（网际互连层）：OSI网络层，解决主机到主机的路由问题。IP、ICMP
>
>网络接入层：对应OSI的物理层和数据链路层，负责相邻的物理节点间的可靠数据传输。ARP、IEEE802.2

TCP/IP参考模型各层常见协议

网络接入层->数据链路层+物理层

> 应用层
>
> HTTP 超文本传输协议 HyperText Transfer Protocol
>
> FTP 文件传输协议 File Transfer Protocol 用于在客户端和服务器之间的文件传输
>
> SMTP 简单邮件传输协议 Simple Mail Transfer Protocol 在网络上传输电子邮件的标准
>
> TELNET 服务器远程登陆控制的标准协议与主要方式
>
> DNS 域名系统（Domain Name System）域名与IP地址相互映射的分布式数据库
>
> ！！！SSH 安全外壳协议（Secure Shell）一种加密的网络传输协议，可以在不安全的网络中为网络服务提供安全的传输环境
>
> ！！！DHCP 动态主机配置协议（Dynamic Host Configuration Protocol）的主要作用是集中管理、动态分配IP地址，提升地址的使用率

> 传输层
>
> TCP 传输控制协议（Transmission Control Protocol）面向连接的、可靠的、基于字节流的传输层通信协议
>
> UDP 用户数据报协议（User Datagram Protocol）是一个简单的、无连接的、不可靠的、面向数据报的通信协议

> 网络层 
>
> IP 网际协议（Internet Protocol）用于**分组交换数据网络**的一种协议，功能包括寻址、路由、尽最大努力交付数据包
>
> ICMP 互联网控制消息协议（Internet Control Message Protocol）用于返回通信环境的错误消息。traceroute ping都是基于ICMP消息实现的。traceroute通过发送含有特殊TTL的包，然后接收ICMP超时消息和目标不可达消息来实现的；ping用ICMP的“Echo request(8)" 和”Echo reply(0)“消息来实现
>
> IGMP
>
> RIP
>
> OSFP
>
> BGP

> 数据链路层
>
> ARP 地址解析协议（Address Resolution Protocol）通过IP寻找MAC地址
>
> ARQ 自动重传请求（Automatic Repeat-reQuest）一种错误纠正协议

> 物理层 
>
> IEEE802 指IEEE标准中关于局域网和城域网的一系列标准，其中最广泛使用的有以太网、令牌环、无线局域网

ARP协议应该属于那一层？一说属于网络层，因为IP协议用ARP协议；另说属于数据链路层，因为MAC地址是数据链路层的内容。OSI模型中，ARP属于链路层，而TCP/IP模型中，ARP协议属于网络层？

### 比较OSI 和TCP/IP

same:

都是层次结构

都可以提供面向连接和无连接的通信服务机制

difference:

OSI七层，TCP/IP四层

OSI是在协议开发前设计的、有清晰概念的模型；TCP/IP是先有协议集然后建立的，事实上得到广泛应用的弱模型，

TCP/IP的网络层只提供无连接的网络服务！！！，OSI的网络层既提供面向连接又提供无连接

OSI传输层只提供面向连接服务；TCP/IP的传输层既提供面向连接的服务TCP也提供无连接的服务UDP！！

### 集线器、网桥、交换机、路由器

网线是物理层硬件

集线器（Hub）是物理层的硬件，连接所有线路，广播所有信息

网桥（Bridge）数据链路层硬件。网桥隔离两个端口，不同端口形成单独的冲突域，减少网内冲突。网桥在不同或相同类型的LAN之间存储并转发数据帧，根据MAC头部来决定转发端口

交换机（Switch）数据链路层。多端口网桥。交换机内部存储MAC表，只会将数据帧发送到指定的目的地址

路由器（Router）网络层硬件，根据IP地址寻址，不同子网间数据传输隔离



### 比特、帧、数据包、数据段、报文

PDU：Prptocol data unit，协议数据单元，对等层协议之间交换的信息单元。PDU再往上就是数据（data）

OSI model，

> 物理层——比特（Bit）
>
> 数据链路层——帧（Frame）
>
> 网络层——分组、数据包（Packet）
>
> 传输层——数据段（Segment）

第五层或以上为数据（Data）。或，应用层信息为消息、报文（message），表示完整的信息。



### MSL、TTL、RTT

MSL（Maximum segment lifetime）：报文最大生存时间。是任何TCP报文在网络上存在的最长时间，超过这个时间的报文会被丢弃。通常30s，1min or 2min

应用：TCP四次挥手，需要TIME-WAIT状态等待2MSL时间，可以保证本次连接产生的所有报文段都在网络中消失

TTL（Time to live）：IP数据报在网络中可存在的总跳数，”生存时间“，但并不是一个真正的时间。由源主机设置，经过一个路由器，跳数减1，如果减至9，则丢弃该数据包，同时发送ICMP报文通知源主机。范围1-255，如果设置的TTL小于传输中需要经过的路由器数量，则该数据包在传输中就会被丢弃。

RTT（Round trip time）：客户端到服务端往返所花时间。RTT受网络传输拥塞的变化而变化，由TCP动态估算。

### TCP的那些事（上）

[TCP 的那些事儿（上） | 酷 壳 - CoolShell](https://coolshell.cn/articles/11564.html)

[TCP 的那些事儿（下） | 酷 壳 - CoolShell](https://coolshell.cn/articles/11609.html)

![img](https://coolshell.cn/wp-content/uploads/2014/05/TCP-Header-01.jpg)

![img](https://coolshell.cn/wp-content/uploads/2014/05/TCP-Header-02.jpg)

Sequence Number 包的序号，解决网络包乱序问题（reordering）

Acknowledgement Number : ACK，用于确定收到，解决不丢包问题

![img](https://coolshell.cn/wp-content/uploads/2014/05/tcpfsm.png)

<img src="https://coolshell.cn/wp-content/uploads/2014/05/tcp_open_close.jpg" alt="img"  />

SYN->Synchronize Sequence Numbers



快速重传机制，Fast Retransmit，不以时间驱动，而以数据驱动重传，

发送方发1，2，3，4，5，第1到，回ack(2)，2没收到，3到，回ack(2)，4，5，都到，回ack(2)，于是三个ack=2，重传2，因为3，4，5，都到，回ack=6

SACK方法：Selective Acknowledgment（SACK），在TCP头加一个SACK，

ACK->Fast Retransmit

SACK->汇报收到的数据碎版

![img](https://coolshell.cn/wp-content/uploads/2014/05/tcp_sack_example-1024x577.jpg)

两边都能知道哪些数据到了，那些没到。Linux下通过tcp_sack参数打开（Linux2.4后默认开）

接收方Reneging，接收方有权把已经报给发送端SACK里的数据丢了。如将内存给其他更重要的东西。因此发送方不能完全依赖SACK，还是要依赖ACK，并维护TIme-out，如果后边ack仍无增长，那么还是要将SACK重传，接收方也不能将SACK的包标记为ack。

！SACK会消耗发送方资源，攻击者给发送方发一堆SACK，会导致发送方开始重传或遍历已发出的数据，消耗发送方资源。

#### Duplicate SACK

D-SACK，使用SACK告诉发送方有哪些数据被重复接收了。

使用SACK的第一个段来标志，如果SACK第一个段的范围被ACK覆盖，则是D-SACK

如果SACK第一个段被SACK的第二个段覆盖，则是D-SACK

example1：ACK丢包

example2：网络延误

1）可以让发送方知道，是发出去的包丢了，还是回来的ACK包丢了。

2）是不是自己的timeout太小了，导致重传。

3）网络上出现了先发的包后到的情况（又称reordering）

4）网络上是不是把我的数据包给复制了。

tcp_dsack参数用于开启此功能，linux2.4后默认开

[TCP 的那些事儿（下） | 酷 壳 - CoolShell](https://coolshell.cn/articles/11609.html)

#### RTT算法

Timeout：长了：重发慢，丢了半天才重发， 效率低，性能差

​					短了：没丢就重发，造成网络拥塞，导致更多超时，导致更多重发

动态设置RTT——Round Trip Time，一个数据包发出去到回来的时间。从而设置TImeout——RTO(Retransmission Timeout)。

#### 经典算法

1）先采样RTT，记下最近几次的RTT

2）平滑计算SRTT（Smoothed RTT）。加权移动平均
$$
SRTT = (\alpha*SRTT)+((1-\alpha)*RTT)
$$
3）计算RTO
$$
RTO = min[UBOUND,max[LBOUND,\beta*SRTT]]
$$
ubound,最大的timeout上限值

lbound，最小的timeout时间，下限

beta-1.3-2.0

#### Karn/Partridge 算法

#### Jacobson/Karels算法



### TCP滑动窗口

TCP必须解决可靠传输以及包乱序（reording）问题，TCP必须知道网络实际的数据处理带宽或者数据处理速度

Sliding Window。TCP头中的字段Window，也叫Advertised-Window，是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端可以根据这个接收端的处理能力来发送数据而不会导致接收端处理不过来。

![img](https://coolshell.cn/wp-content/uploads/2014/05/sliding_window.jpg)

接收端给发送端回ACK中会汇报自己的AdvertisedWIndow = MaxRcvbuffer - LastByteRcvd-1

发送方根据这个窗口控制发送数据大小，保证接收方可处理

![img](https://coolshell.cn/wp-content/uploads/2014/05/tcpswwindows.png)

#1已经收到ACK确认

#2发了但没收到ACK

#3没发但能发的（接收方有空间）

#4接收方没空间的

#### zero window

ZWP（Zero Window Probe），发送端在窗口变0后，会发ZWP包给接收方，让接收方来ack它的Window尺寸，一般设置三次，30s-60s

只要等待的地方都可能DDoS攻击，攻击者会在和HTTP建好链发完GET请求后，把WIndow设置0，然后服务端只能等待进行ZWP，攻击者并发大量这样的请求，导致服务器端资源耗尽



#### Silly Window Syndrome

#### Nagle算法

如果接收端处理过慢，每次window只能接受几个byte，当发送段每次都发送这几个字节时，会有大量带宽浪费在TCPIP头部上。Nagle工作方式是[缓存/累计]要发送的小数据直到window>=MSS时一并发送，避免对小的window做出相应

（Max Segment Size）

### TCP拥塞处理-CongestionHandling

Sliding Window来做Flow Control

TCP不是一个自私的协议，当拥塞发生的时候，要做自我牺牲。

拥塞控制四个算法：1）慢启动，2）拥塞避免，3）拥塞发生，4）快速恢复



#### 慢启动 Slow Start

刚刚加入网络的连接，一点点地提速。

（cwnd Congestion Window）：

1）连接建好的开始初始化cwnd = 1，表示可传一个MSS大小的数据（1500-40）

2）收到一个ACK，cwnd++，线性上升

3）每过一个RTT，cwnd=cwnd*2；指数上升

4）ssthresh（slow start threshold)，是个上限，当cwnd>=sshresh，进入“拥塞避免算法”

网速快->ACK快->RTT短->启动并不慢

#### 拥塞避免算法 Congestion Avoidance

cwnd>=ssthresh，进入Congestion Avoidance。一般ssthresh = 65535，单位字节

1）收到一个ACK，cwnd = cwnd +1/cwnd

2）每过一个RTT，cwnd = cwnd+1

避免过快增长，慢慢调整到网络最佳值，线性上升

#### 拥塞状态的算法

丢包时

1）等到RTO超时，重传数据包。反应强烈

sshthresh = cwnd/2

cwnd重置1

进入慢启动

2）Fast Retransmit 算法，当收到3个D-ACK时开启重传，不用等到RTO超时

TCP Tahoe和RTO超时一样

TCP Reno：

cwnd=cwnd/2

sshthresh = cwnd

进入快速恢复算法FastRecovery

### 快速恢复算法

TCP Reno

如果存在3个DACK说明网络也不差，因此反应没有RTO超时那么强烈。进入FastRecovery前，cwnd和sshresh已经被更新

之后：

cwnd = sshthresh +3*MSS（3个数据包收到了）

重传Duplicated ACKs指定数据包

如果再次收到DACK，cwnd=cwnd+1

如果收到新ACK，则cwnd = sshthresh，进入拥塞避免算法



流量控制是接收端控制的，拥塞避免是发送端控制的。最终都是控制发送端的发送速率。

### TCP标志位

标志位代表了当前请求的目的。

1.SYN（synchronous）：发送/同步标志，用来建立连接，与ACK标志位搭配。A请求与B建立连接，SYN=1,ACK=0;B确认与A建立连接时，SYN=1，ACK=1；

2.ACK（acknowledgement）：确认标志，表示确认收到请求

3.PSH（push）：推送操作，数据包到达接收端后，不对其进行队列处理，而是尽可能将数据交给应用程序处理

4.FIN（finish）：结束标志，表示关闭一个TCP连接

5.RST（reset）重置复位标志，用于复位对应的TCP连接

6.URG（urgent）：紧急，用于保证TCP连接不被中断，并督促中间层设备尽快处理

SYN flag = 1,表示当前连接的初始序列号（Initial Sequence Number，ISN）

SYN flag = 0，表示当前报文段中的第一个字节的序列号

- 第一次握手：服务端确认“自己收、客户端发”报文功能正常
- 第二次握手：客户端确认“自己发、自己收、服务端收、客户端发”报文功能正常，客户端认为连接已建立
- 第三次握手：服务端确认“自己发、客户端收”报文功能正常，此时双方均建立连接，可以正常通信

### TCP粘包

TCP基于字节流，数据块是没有边界、没有结构的字节流，因此可能产生粘包

1.发送方为了将多个发往接收端的包，更有效地发到对方，使用了优化方法（Nagle算法），将多次间隔较小、数据量小的数据包，合并城一个大的数据包一次性发送

2.接收方不能及时读，导致缓冲区中多个包粘连



解决：

1.发送方关闭Nagle算法

2.。。。。。。。。。。。

### HTTP请求方法

请求方法表明了要对给定资源执行的操作，每个请求方法都实现了不同的语义。包括GET、HEAD、POST、PUT、PATCH、DELETE、OPTIONS以及不常用的CONNECT、TRACE

> GET：获取服务器的指定资源
>
> HEAD：与GET一样，都是发出一个获取服务器指定资源的请求，但服务器只会返回Header而不会返回Body。用于确认URI的有效性及资源更新的日期时间等。一个典型应用是下载文件时，先通过HEAD方法获取Header，从中读取文件大小Content-length；再配合Range字段、分片下载服务器资源
>
> POST：提交资源到服务器/在服务器新建资源
>
> PUT：替换整个目标资源
>
> PATCH：替换目标资源的==部分内容==
>
> DELETE：删除指定的资源
>
> OPTIONS：用于描述目标资源的通信选项。可以用于检测服务器支持哪些HTTP方法，或者在CORS中发起一个预检请求，以检测实际请求是否可以被服务器所接受
>
> CONNECT：建立一个由目标资源标识的服务器的隧道
>
> TRACE：执行一个消息环回测试，返回到服务端的路径。客户端请求连接到目标服务器时可能会通过代理中转，通过TRACE方法可以查询发送出去的请求的一系列操作。

幂等的：一个HTTP方法是幂等的，指同样的请求执行一次与多次效果是一样的，幂等方法不应该具有副作用。

幂等：GET HEAD PUT DELETE OPTIONS

非幂等：POST

安全的：一个HTTP方法是安全的，指的是这是一个对服务器只读操作的方法，不会修改服务器数据。

安全方法：GET HEAD OPTIONS

不安全：PUT DELETE POST

所有安全方法都是幂等的，

可缓存的：GET HEAD

### GET 和 POST区别

### HTTP状态码

#### 信息响应（100-199）

​	100 Continue：表明到目前为止都很正常，客户端可以继续发送请求或者忽略这个响应

#### 成功响应（200-299）

​	200 OK

​	201 Created：该请求已成功，并因此创建了一个新的资源。这通常是在POST请求之后返回的响应

​	204 No Content：该请求已成功处理，但是返回的响应报文不包含实体的主体部分。通常用于只需要从客户端向服务器发送信息而不需要返回数据时。

​	206 Partial Content：服务器已经处理了部分GET请求，该请求必须包含Range头信息来指示客户端希望得到的内容范围。通常使用此类响应来实现断点续传，或将大文档切片并行下载。

#### 重定向（300-399）

​	301 Moved Permanently：永久性重定向

​	302 Found：临时性重定向。常用，通过302跳转将所有HTTP流量重定向到HTTPS

​	303 See Other：与302相同功能，303明确要求客户端应采用GET方法获取资源

​	304 Not Modified：如果客户端发送了一个带条件的GET请求且该请求已被允许，儿文档内容并没有改变，则服务器应当返回这个状态码。304响应不包括消息体

​	307 Temporary Redirect：临时重定向。307可以确保请求方法和消息主体不会发生变化；302的话一些旧哭护短会错误的将请求方法转换为GET

#### 客户端错误（400-499）

​	400 Bad Request：请求报文中存在语法错误，或者参数有误

​	401 Unauthorized：未认证（没登陆）

​	403 Forbidden： 没有权限（登陆了但没权限）

​	404 Not Found

​	405 Method Not Allowed

#### 服务器错误（500-599）

500 Internal Server Error

502 Bad Gateway

503 Service Unavailable

#### 302，302，307重定向原理

返回的Header中有一个Location字段指向目标URL，浏览器会重定向到这个URL

#### 304与缓存机制

强制缓存，协商缓存

#### Cookie和Session

都是用来跟踪浏览器用户身份的会话方式

Cookie：

​	存在浏览器里，可设置过期时间

​	每次访问服务器，浏览器会在header中携带cookie

​	如果浏览器禁用，可用URL重写机制，将信息保存在URL

Session：

​	In Server，一段时间Session失效

​	本质上还是由Cookie实现，浏览器的cookie中保存一个sessionId，其他信息再服务器

​	Session失效，是因为服务器设置了失效时间，如果用户长时间不交互，则销毁Session（30min）；交互的话，就会刷新Session

​	

#### a

限制对象只能建立在堆上：

```c++
class A
{
protected:
    A() {}
    ~A() {}

public:
    static A *create()
    {
        return new A();
    }
    void destory()
    {
        delete this;
    }
};

```

限制对象只能建立在栈上

```c++
class A
{
private:
    void *operator new(size_t t) {}    // 注意函数的第一个参数和返回值都是固定的
    void operator delete(void *ptr) {} // 重载了 new 就需要重载 delete
public:
    A() {}
    ~A() {}
};

```

1. 静态成员变量可以作为成员函数的参数，而普通成员变量不可以。

4.静态数据成员的类型可以是所属类的类型，而普通数据成员的类型只能是该类类型的指针或引用。

1. 静态成员函数不能调用非静态成员变量或者非静态成员函数，因为静态成员函数没有 `this` 指针。静态成员函数做为类作用域的全局函数。

1. 静态成员函数不能声明成虚函数（`virtual`）、`const` 函数和 `volatile` 函数。

类内定义成员函数默认是内联函数
在类内定义成员函数，可以不用在函数头部加 inline 关键字，因为编译器会自动将类内定义的函数（构造函数、析构函数、普通成员函数等）声明为内联函数

可以在声明函数和定义函数的同时加上 inline；也可以只在函数声明时加 inline，而定义函数时不加 inline。只要确保在调用该函数之前把 inline 的信息告知编译器即可。



内联函数的作用：
消除函数调用的开销。
在内联函数出现之前，程序员通常用 #define 定义一些“函数”来消除调用这些函数的开销。内联函数设计的目的之一，就是取代 #define 的这项功能（因为使用 #define 定义的那些“函数”，编译器不会检查其参数的正确性等，而使用 inline 定义的函数，和普通函数一样，可以被编译器检查，这样有利于尽早发现错误）。
去除函数只能定义一次的限制。
内联函数可以在头文件中被定义，并被多个 .cpp 文件 include，而不会有重定义错误。这也是设计内联函数的主要目的之一。

关于减少函数调用的开销：
内联函数一定会被编译器在调用点展开吗？
错，inline 只是对编译器的建议，而非命令。编译器可以选择忽视 inline。当程序员定义的 inline 函数包含复杂递归，或者 inlinie 函数本身比较长，编译器一般不会将其展开，而仍然会选择函数调用。
“调用”普通函数时，一定是调用吗？
错，即使是普通函数，编译器也可以选择进行优化，将普通函数在“调用”点展开。
既然内联函数在编译阶段已经在调用点被展开，那么程序运行时，对应的内存中不包含内联函数的定义，对吗？
错。
首先，如第一点所言，编译器可以选择调用内联函数，而非展开内联函数。因此，内存中仍然需要一份内联函数的定义，以供调用。
而且，一致性是所有语言都应该遵守的准则。普通函数可以有指向它的函数指针，那么，内敛函数也可以有指向它的函数指针，因此，内存中需要一份内联函数的定义，使得这样的函数指针可以存在。



堆区和自由存储区的区别与联系：
（1）malloc申请的内存在堆上，使用free释放。new申请的内存在自由存储区，用delete释放
（2）堆（heap）是c语言和操作系统的术语。堆是操作系统所维护的一块特殊内存，它提供了动态分配的功能，当程序运行时调用malloc()时就会从中分配，调用free可把内存交换。而自由存储区是C++中通过new和delete动态分配和释放对象的抽象概念，通过new来申请的内存区域可称为自由存储区。基本上，所有的C++编译器默认用堆来实现自由存储区，也即是缺省的全局运算符new和delete也许会按照malloc和free的方式来实现，这时由new运算符分配的对象，说它在堆上也对，说它在自由存储区也对。
记住：
（1）堆是c语言和操作系统的术语，是操作系统维护的一块内存。自由存储是C++中通过new和delete动态分配和释放对象的抽象概念。
（2）new所申请的内存区域在C++中称为自由存储区，编译器用malloc和free实现new和delete操作符时，new申请的内存可以说是在堆上。
（3）堆和自由内存区有相同之处，但并不等价。

new会调用构造函数，delete会调用析构函数，而malloc()和free()则不会调用构造函数和析构函数。

///

摘自《程序员的自我修养》中原话：
我们可以使用volatile关键字试图阻止过度优化，volatile基本可以做到两件事情：

（1）阻止编译器为了提高速度将一个变量缓存到寄存器内而不写回；（缓存一致性协议、轻量级同步）

（2）阻止编译器调整操作volatile变量的指令排序。

即使volatile能够阻止编译器调整顺序，也无法阻止CPU动态调度换序。

要保证线程安全，阻止CPU换序是必须的。遗憾的是，现在并不存在可移植的阻止换序的方法。
通常情况下是调用CPU提供的一条指令，这条指令常常被称为barrier。
一条barrier指令会阻止CPU将该指令之前的指令交换到barrier之后。
对volatile的三点理解：
1. 只能保证赋值原子性，复合操作不能保证；
2. 告诉编译器不进行指令重排（JMM中还会追加CPU内存屏障），以避免过度优化；
3. 保证内存可见性。

欢迎补充、修改。

作者：天狼星空凛
链接：https://leetcode-cn.com/leetbook/read/cpp-interview-highlights/oxui3e/?discussion=3iUNM6
来源：力扣（LeetCode）
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

///



单一职责原则：控制类的粒度大小，将对象解耦，提高其内聚性
开放封闭原则： 对扩展开放对修改关闭
里氏替换原则： 继承类必须确保父类所拥有的性质在子类中国仍然成立
依赖倒转原则：面向接口编程不要面向实现编程
迪米特原则： 只与你的朋友交流，不要与陌生人说话
接口隔离原则：要为各个类建立它们需要的专用接口。
合成复用原则： 尽量先使用组合或聚合关联关系，其次才考虑使用继承来实现。
（狂神说总结的OOP七大原则，感觉可以参考记忆）

![image-20220309212520122](C:\Users\call1\AppData\Roaming\Typora\typora-user-images\image-20220309212520122.png)

### 数据库

基本概念

数据（data）：描述事物的符号记录称为数据

hash表索引缺点：

MRR 

FIC

索引覆盖

hyperloglog

limit 10000,5 

limit 5

如何实现相应的原理

A原子性:由undo log日志保证，它记录了需要回滚的日志信息，事务回滚时撤销已经执行成功的sql
C一致性:一般由代码层面来保证
I隔离性:由MVCC来保证
D持久性:由内存+redo log来保证，mysql修改数据同时在内存和redo log记录这次操作，事务提交的时候通过redo log刷盘，宕机的时候可以从redo log恢复

	归档日志 bin log
	回滚日志 undo log
	重做日志 redo log
	原子性：
		undo log日志记录sql操作，当发生回滚时，逆序执行逆操作来完成回滚
	持久性：
		bin log & redo log日志，
		redo log: 为了避免每次读取数据都进行磁盘IO，MySQL的InnoDB引擎采用缓存buffer方式
		redo log分为两个部分：缓冲区的redolog buffer和磁盘上的redologfile
		磁盘上的redo log不受宕机影响，在每次真正执行DML操作之前先更新redo log（称为预写式日志），也就是WAL技术
			WAL技术（Write-Ahead Logging）：在真正把数据写入到磁盘前，先记录日志
			redo log（undo log跟redo log的机制一样）都经历一次写，一次刷
				写过程将引擎用户层buffer记录的数据写入核心层buffer
				刷过程将核心层buffer数据真正写入磁盘
			由此分为三种写刷时机，同样由参数控制：延迟写 / 实时写，实时刷 / 实时写，延迟刷
			bin log有类似的刷盘时机机制，同样由参数控制：不强制要求 / 每次提交都刷盘（默认） / 集齐N次提交后刷盘
		由于redo log采用循环写的方式记录下最近的操作，但要用到更久以前的操作来完成恢复时，就需要另一种日志对更久之前的操作归档
		这个日志就是bin log, 两者要配合使用才能保证当数据库发生宕机重启时，数据不会丢失
		MySQL提交时，分为两阶段提交，第一阶段提交时，执行器先写redo log(prepare),再写bin log,第二阶段提交时正式更新redo log(commit),保证两个日志数据的安全与同步
		bin log与redo log区别：
			redo log循环写，大小固定，会丢失；bin log追加写，大小通过配置参数决定，追加写到超过文件大小后会将后续日志记录到新的bin log不丢失
			redo log 适用于崩溃恢复，只有redo log是crush-safe的；binlog 除了配合崩溃恢复保证持久性之外，还适用于主从复制（也是重点）
			bin log所有引擎都支持，server层实现，redo log仅InnoDB支持，引擎层实现
			bin log支持三种记录方式（Statement / Row / Mixed），日志类型为逻辑日志；
			redo log日志类型为物理日志（物理日志用于恢复速度会快很多）
	一致性：
		bin log 也有类似的缓冲区，binlog刷盘时机同样是靠配置参数来控制
		可以选择不实时更新，牺牲一定的一致性来换取更好的性能，默认每次提交都刷盘（保证一致性）
	隔离性：
		事务隔离级别：     	   防脏读  防不可重复读  防幻读
			read uncommitted     X          X          X
			read committed       √          X          X
			repeatable read      √          √          X
			serializable         √          √          √
			脏读：读未提交
			不可重复读：同一事务两次读的结果不同（针对update）
			幻读：前后多次读取，数据总量不一致（针对insert、delete）
		MVCC：多版本并发控制，不同事务的读–写、写–读操作并发执行，从而提升系统性能
			读未提交：就全读最新的就是读未提交，不加任何判断
			读已提交和可重复读的实现：
				核心处理逻辑就是判断所有版本中哪个版本是当前事务可见的，称为 ReadView
				这个过程通过事务IDtrx_id来判断，这个ID严格递增
				读已提交：仅判断trx_id，在本次事务之前的都有效修改，可查
				可重复读：利用undo log，配合ReadView，当该事务执行相同读操作的时候，依据undo log恢复到开始时的数据，保证永远是第一次查询时的结果	
			串行化的实现：锁实现串行化，牺牲并发，保证ACID
	注意：以上三大日志都仅记录写入性操作，不包括查询操作（因为查询不更改数据库，也就没必要记录了）

锁机制

SQL语句

数据定义语言DDL（Data Definition Language）：CREATE，DROP，ALTER，表结构，视图，索引

数据查询语言DQL（Data Query Language）：SELECT

数据操纵语言DML（Data Manipulation Language）：INSERT UPDATE，DELETE。DQL+DML=CRUD

数据控制功能DCL（Data Control Language）：GRANT，REVOKE，COMMIT，ROLLBACK，对数据库安全性、完整性有操作的，可理解为权限控制。

### 键

- 超键：关系中能唯一标识元组的属性集称为关系模式的超键。包括候选键和主键。
- 候选键：最小超键，没有冗杂元素的超键
- 主键：表中对储存数据对象予以唯一和完整标识的数据列或属性的组合。一个数据列只能有一个主键，且值不能缺失（NULL）
- 外键：一个表中存在另一个表的主键称为此表的外键，外键可有重复，可空。用来和其他表建立联系。

![img](https://www.runoob.com/wp-content/uploads/2019/01/sql-join.png)

**主从复制原理**

【文件描述】
主库: 
	binlog 二进制日志文件
从库: 
	relaylog  中继日志
	master.info  主库信息文件
	relaylog.info relaylog应用的信息

主库:
	Binlog_Dump Thread : DUMP_T 	-- 二进制转储线程，主从连接后把二进制日志发送给从库
从库: 
	slave_IO_Thread     : IO_T 	-- 接到主库，向主库发生请求更新binlog
	slave_SQL_Thread    : SQL_T 	-- 读取从库的中继日志，并且执行日志中的事件

![图片.png](https://pic.leetcode-cn.com/1635672922-VLDCRK-file_1635672923503)

1.从库执行change master to 命令(主库的连接信息+复制的起点)
2.从库会将以上信息,记录到master.info文件
3.从库执行 start slave 命令,立即开启IO_T和SQL_T
4.从库 IO_T,读取master.info文件中的信息
	获取到IP,port,User,Pass,binlog的位置信息
5. 从库IO_T请求连接主库,主库专门提供一个DUMP_T,负责和IO_T交互
6. IO_T根据binlog的位置信息或(GTID),请求主库新的binlog
7. 主库通过DUMP_T将最新的binlog,通过网络TP(传送)给从库的IO_T
8. IO_T接收到新的binlog日志,存储到TCP/IP缓存,立即返回ACK给主库,并更新master.info
9. IO_T将TCP/IP缓存中数据,转储到磁盘relaylog中.
10. SQL_T读取relay.info中的信息,获取到上次已经应用过的relaylog的位置信息
11. SQL_T会按照上次的位置点回放最新的relaylog,再次更新relay.info信息
12. 从库会自动清除应用过relaylog(中继日志文件),避免占用过多的磁盘空间



LC147

TOPk





树状数组

```c++
x & -x == x & (~x + 1)
```

 一般可以用来获取某个二进制数的LowBit

![binaryindexedtreeexpandedtreewithinfo.gif](https://pic.leetcode-cn.com/755dd21358e8cd6ac39c85bdbaa67188dcf67dad7bd8c32d4ad777c1f376ff08-binaryindexedtreeexpandedtreewithinfo.gif)

#### 4级流水线

> Fetch通过程序计数器读取对应的内存地址
>
> Decode对指令进行解码
>
> Execution CPU执行指令
>
> Store CPU将计算结果存回寄存器或将寄存器值存入内存
>
> 这四个阶段成为指令周期（Instruction Cycle）

#### 指令执行速度

硬件参数GHz，1GHz的CPU，时钟频率1G，1秒产生1G次数的脉冲信号，1次脉冲信号的高低电平转换就是1周期，称为时钟周期。

CPU在1时钟周期中仅能完成一个最基本的动作。

程序的CPU执行时间 = CPU时钟周期数*时钟周期时间

2.4GHz主频，时钟周期时间1/2.4G（1/2G = 0.5ns）

主频很难在提高，减少CPU时钟周期数，

CPU时钟周期数 = 指令数*每条指令的平均时钟周期数（Cycles Per Instruction）CPI

- 指令数：执行程序需要多少条指令，及哪些指令。基本靠编译器优化。
- CPI：1条指令需要多少时钟周期数，CPU通过Pipeline，让一条指令需要的CPI尽可能少
- 时钟周期时间：主频，硬件



寄存器数量在几十到几百，64位1个寄存器储存8字节。

CPU Cache：SRAM（Static Random-Access Memory，静态随机储存器）

1bit数据需要6个晶体管

- L1高速缓存：访问速度几乎和寄存器一样快，2~4个时钟周期，大小几十KB—几百KB，每个CPU核都有自己的L1缓存，指令和数据在L1分开放，分为指令缓存和数据缓存。

- L2高速缓存：百KB-几MB，10-20时钟周期，
- L3高速：多个CPU核心公用，几MB到几十MB，20-60时钟周期

内存，DRAM（Dynamic Random Access Memory）

比SRAM密度更高，功耗低，更大容量。存1bit需要1个晶体管和1电容，数据储存在电容，电容会漏电，需要定时刷新电容所以dynamic。

内存速度200-300时钟周期。

SSD/HDD：内存读写比SSD快大概10-1000倍

HDD（Hard Disk Drive）比内存慢10w倍



CPU需要访问位于内存的某个数据，先从寄存器找，没有去L1，没有去L2,L3，都没有才去内存。

#### 内存管理

操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。

程序想要访问虚拟地址时，由操作系统给转换为不同的物理地址，这样不同进程运行时，写入的是不同物理地址，这样就避免了冲突。

程序使用的内存地址：虚拟内存地址（Virtual Memory Address）

硬件中的空间地址：物理内存地址（Physical Memory Address）

CPU-》虚拟地址-》MMU（内存管理单元）-》物理地址

操作系统通过内存分段和内存分页管理虚拟和物理关系。

减少内存碎片，避免内存交换的空间太大

内存分页（Paging）

分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，叫页（Page）Linux下一页为4KB。

当进程访问的虚拟地址在页表中查不到，系统会产生一个缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后返回用户空间，恢复进程运行。

- 分页如何解决分段的内存碎片、内存交换效率低的问题？

内存空间都是预先划分好的，不会像分段一样产生间隙非常小的内存。并且释放的内存都是以页为单位释放的，也不会产生无法给进程使用的小内存。

如果内存不够，OS会把其他正运行着的进程中，最近没被使用的内存页面给释放掉，即暂时写道硬盘上，称为换出。需要的时候再换回来，称为换入（Swap in）。一次性写入磁盘的只有少数页，内存交换效率较高。

moreover，分页使加载程序时，不必一次性都把程序加载到物理内存中。只有在程序运行中，需要用到对应虚拟内存页里的指令和数据时，再加载到物理内存中。

- 分页机制下虚拟地址和物理地址如何映射？

分页机制下，虚拟地址分页号和页内偏移。页号为页表的索引，页表包含物理页每页所在物理内存基址，这个基址与业内偏移组成物理内存地址。

3步骤：1、将虚拟内存地址切割成页号和偏移量

2、根据页号，从页表里查询物理页号

3、根据物理页号+偏移量，得到物理内存地址。

- 简单分页的缺陷？

OS可以运行很多进程，就意味着页表非常庞大。

32位环境，虚拟地址空间4GB，假设1页4KB（2^12），则需要100w个页，每个页表项用4字节储存，则4GB空间映射有4MB内存来储存页表。

每个进程都有自己的虚拟地址空间，即自己的页表。

100进程，400MB储存页表。

64位系统更大。

#### 多级页表（Multi-Level Page Table）

32位虚拟地址，分10位一级页号，10位二级页号，12位页内偏移。

4GB内存，100万页表项，1级页表1024个页表，每个页表包含1024个页表项，为二级分页

二级分页，一级页表就可以覆盖整个4GB虚拟地址空间，当如果某个一级页表的页表项没有被用到，就不用创建这个页表项对应的二级页表了，只有在需要的时候才会创建二级页表。

如果只有20%一级页表项被用到，则空间4KB+20%*4MB = 0.804MB

64位系统有四级目录

> 全局页目录项PGD（Page Global Directory）
>
> 上层页目录项PUD（Page Upper Directory）
>
> 中间页目录项PMD（Page Middle Directory）
>
> 页表项PTE（Page Table Entry）

#### TLB

程序是局部性的，一段时间内，程序的执行仅限于程序的某一部分。即所访问的储存空间也局限于某个内存区域。

最常用的几个页表项放在访问速度更快的硬件，CPU芯片中有TLB-》存放最常访问的页表项Cache，（Translation Lookaside buffer），页表缓存、转址旁路缓存、快表。

#### 段页式内存管理

- 先把程序划分为几个有逻辑意义的段，即分段机制
- 再将每个段划分为多个页，对分段划分出来的连续空间划分固定大小的页。

每个程序一个段表，每个段建立一张页表，段表中地址是页表起始地址，页表地址是某页的物理页号。

3次内存访问：

第一次访问段表，得页表起始地址

第二次访问页表，得物理页号

第三次物理页号+页内偏移，得物理地址



用户内存空间，从低地址到高：

程序文件段.text 二进制可执行代码；

已初始化数据段，包括静态常量：.rodata

未初始化数据段，包括未初始化得静态常量.bss

堆段动态分配内存，从低地址到高

文件映射段：动态库、共享内存

栈段，局部变量和函数调用的上下文。大小固定8MB。也有参数可以调整

堆malloc()

文件映射段mmap()

#### 进程

代码储存在硬盘的静态文件，经过编译成为二进制可执行文件，加载到内存，CPU执行其中每一条指令，则这个程序称作进程（process）

当进程需要读取硬盘中数据时，不会进行阻塞等待数据返回，而是执行其他进程，当数据返回，进程给CPU发送中断，接收到后恢复进程1

多个程序、交替进行。

每个进程执行几十几百毫秒，1s内运行很多进程，产生并行的错觉，实际上是并发。

并发-》1个核交替执行不同进程

并行-》多个核同时执行各自进程。



进程状态：运行、阻塞、就绪、创建状态、结束状态

进程没有占用实际物理内存的情况：挂起状态

挂起状态：阻塞挂起：进程在外存等待某个事件出现

就绪挂起：进程在外存，但进入内存时，立即运行。

挂起其他原因：sleep让进程间歇性挂起，设置一个定时器，到期后唤醒进程。

用户挂起Ctrl+Z

### PCB进程控制块（Process control block）

PCB是进程存在的唯一标识

包含信息：

进程描述信息：

- 进程标识符：标识各个进程，每个进程都有一个且唯一的标识符
- 用户标识符：进程归属的用户，为共享和保护

进程控制和管理信息：

- 当前状态：new、ready、running、waiting、blocked
- 进程优先级

资源分配清单：

#### 进程的控制

#### 线程

线程是进程当中的一条执行流程。

同个进程中的线程可以共享代码段、数据段、打开的文件，但每个线程各自有一套独立的寄存器和栈，以确保线程的控制流是相对独立的。

缺点：进程中的一个线程崩溃时，会导致所属进程的所有线程崩溃

比较：

进程是资源（内存、打开的文件）分配的单位，线程是CPU调度的单位

进程有完整的资源平台，线程只独占必不可少的资源，寄存器和栈

线程同样有运行就绪阻塞三状态，同样有状态的转换关系

线程可以减少并发执行时间和空间开销。

减少开销->

线程创建时间短

线程终止时间短，释放资源快

线程切换比进程切换快，线程共享同一个页表，进程切换需要切换页表

线程间数据传递不需要经过内核。

#### 线程实现

### 进程间通信

进程的用户地址空间是独立的，一般而言是不能互相访问的，但内核空间是共享的，所以进程通信必须通过内核。

##### 管道

|

mkfifo

管道效率低，不适合进程间频繁进行交换数据。

管道实际上是内核中的一串缓存，一段写入的数据实际上是缓存在内核中的，另一端读取也就是从内核中读取。管道传输的数据无格式流，且大小受限。



##### 消息队列

保存在内核中的消息链表

通信不及时

不适合大数据传输，内核中的每个消息体有最大长度限制，且全部消息体的总长度也有上限。MSGMAX和MSGMNB分别是消息最大长度和队列最大长度

通信过程中存在用户态和内核态之间的数据拷贝开销。

##### 共享内存

机制：拿出一块虚拟地址空间，映射到相同的物理内存。因此不用拷贝，提高进程间通信速度。

##### 信号量

对于共享内存方式，如果多个进程同时修改一共享内存，会发生冲突，先写的进程会发现内容被覆盖了。

所以需要保护机制，共享资源任意时刻只能被一个进程访问。信号量来实现。

信号量是个整型计数器，用于实现进程间的互斥和同步。而不缓存进程间通信的数据。

信号量是资源的数量，2原子操作来控制信号量。

P操作：信号量-1，后如果信号量<0，则资源被占用，进程阻塞等待；如果信号量>=0，则资源可用，进程继续执行

V操作：信号量+1，后如果信号量<=0，则当前有阻塞进程，将该进程唤醒运行；如果信号量>0，则无阻塞进程。

P是进入共享资源之前，V是出共享资源之后，必须成对。

信号初始化1，代表互斥信号量，保证共享内存在任何时刻只有一个进程访问。

多进程同步，初始信号量0，同步信号量。

A进程：生成数据->V操作

B进程：P操作->读取数据

同步信号量保证进程A在进程B之前执行

##### 信号

异常下的工作模式，需要信号来通知进程。

kill -l 所有信号

Ctrl+C SIGINT 终止该进程

CTRL+Z SIGTSTP 停止该进程，但未结束

硬件来源：键盘

软件来源：kill

唯一的异步通信机制，可以在任何时候发送信号给某一进程。

用户进程的处理方式：

1、默认操作。Linux的规定

2、捕捉信号。可以定义信号处理函数。

3、忽略。SIGKILL和SEGSTOP不可捕捉和忽略，用于中断和结束某一进程。



#### Socket

跨网络与不同主机上的进程通信，需要Socket

也可以同主机上进程间通信

```
int socket(int domain, int type, int protocal)
```

domain指定协议族，AF_INET  IPV4, AF_INET6 IPV6, AF_LOCAL/AF_UNIX 本机

type指定通信特性，SOCK_STREAM字节流，TCP，SOCK_DGRAM数据报，对应UDP

protocal废弃0

本地字节流socket和本地数据报socket在bind时，不需要绑定IP地址和端口，而是绑定一个本地文件。

线程间关注的不是通信方式，因为共享资源都可以做到线程间通信，多线程竞争共享资源的问题更大，也可以用信号量来实现同步互斥

### 多线程同步

并发进程/线程在一些关键点可能需要互相等待与互通消息，这种互相制约的等待与互通信息成为进程/线程同步

同步：操作A必须在操作B之前执行，操作C必须在操作AB完成之后才能执行

互斥：操作A和操作B不能再同一时刻执行

#### 实现同步互斥

- 锁：加锁，解锁
- 信号量：PV

忙等待锁和无忙等待锁

忙等待锁：原子操作指令--测试和置位（Test-and-Set）

原子操作要么全部执行，要么全部执行，不能出现执行到一半的中间状态。

````c++
int TestAndSet(int *old_ptr, int new){
	int old = *old_ptr;
	_old_ptr = new;
	return old;
}
````

#### 死锁

死锁的概念

两个线程为了保护两个不同的共享资源使用了两个互斥锁，这两个锁应用不当时，可能会造成两个线程都等待对方释放锁，在无外力作用下，这些线程会一直相互等待，无法继续运行。

死锁4条件：

互斥条件、持有并等待、不可剥夺、环路等待

互斥条件：多个线程不能同时使用同一资源

持有并等待：线程A持有资源1，想申请资源2，但2被线程C持有，A就会等待，但等待的同时不会释放自己已经持有的资源1

不可剥夺：当线程已经持有资源，在自己使用完之前不能被其他线程获取，（非抢占），如果线程B想用，必须得线程A释放之后才能获取。

环路等待：死锁发生时，两线程获取资源的顺序构成环形。

#### 避免死锁

使用资源有序分配法，以破坏环路等待条件。

线程AB获取资源的顺序要一样，线程A先获取A在获取B，B也需要是同样的顺序。

#### 锁

最底层的锁是互斥锁和自旋锁。

当已有一个线程加锁后，其他线程加锁则会失败

- 互斥锁加锁失败后，线程会释放CPU，给其他线程
- 自旋锁加锁失败后，线程会忙等待，知道他拿到锁



#### 读写锁

适用于能够明确区分读操作和写操作的场景

- 当写锁没被线程占用，多个线程可以并发持有读锁，提高了共享资源的访问效率。
- 一旦写锁被占用，该线程的读锁操作会被阻塞，并且其他写线程的获取写锁的操作也会被阻塞。

读写锁在读多写少的场景能发挥优势

也分 读优先锁和写优先锁

读优先锁：读线程A获取读锁，写线程B想获取写锁，阻塞，后续读线程B进入仍可以继续获取读锁

写优先：读线程A获取读锁，写B想获取写锁，阻塞，后续读B进入无法获取读锁，A线程结束唤醒写B，成功获取写锁

读优先会导致写线程饥饿

写优先会导致读线程饥饿

公平读写锁横空出世：用队列把获取锁的线程排队，不管读写都是FIFO，这样读线程仍可以并发，也不会出现饥饿。

读写锁可以根据场景选择互斥锁和自旋锁其中一个实现。

#### 乐观锁和悲观锁

上述互斥、自旋、读写锁都是悲观锁。

悲观锁认为多线程同时修改共享资源概率很高，于是容易出现冲突，所以访问资源前都要上锁。

如果多线程同时修改概率低，可用乐观锁。

工作方式of乐观锁：先修改完共享资源，再验证这段时间内有无冲突，如果没有其他线程修改，则操作完成，如果有其他线程已修改，则放弃操作。至于重试的代价，如果冲突概率足够低，是可以接受的。

乐观锁全程不加锁，也叫无锁编程。

在线文档：先让用户编辑文档，浏览器下载时会记录服务端返回的文档版本号。当用户提交修改，发送给服务端的请求会带上原始版本号，服务端将版本号对比，如果一致则完成修改，否则提交失败。

SVN和Git也是用了乐观锁思想。

#### 调度算法

#### 进程调度算法

也叫CPU调度算法

1、进程从运行状态到等待状态

2、进程从运行状态到就绪状态

3、等待到就绪状态（优先级原则时，一个进程处于等待，优先级高，如果等待事件发生了，就转到就绪，会立刻抢占正在运行的进程）

4、运行到终止

1、4调度为非抢占式调度，必须直到进程完成或者因发生某个时间而被阻塞，才会切换进程

2、3为抢占式调度，时间片调度、优先级原则、短作业优先原则。

调度算法影响的是等待时间（进程在就绪q中等待调度的时间总和）

先来先服务调度算法

First Come First Served FCFS

有利于长作业，适用于CPU繁忙作业系统，不适合I/O繁忙作业

最短作业优先

Shortest Job First，SJF

提高系统吞吐量

高响应比优先调度算法

Highest Response Ratio Next， HRRN

进程调度前，先计算响应比优先级
$$
优先级 = \frac{等待时间+要求服务时间}{要求服务时间}
$$
时间片轮转调度算法

Round Robin，RR

每个进程分配一个quantum时间片，

最高优先级调度算法

多级反馈队列调度算法

Multilevel Feedback Queue（MFQ）

多级：有多个队列，优先级从高到低，优先级越高时间片越短

反馈：新的进程如果加入优先级高队列，立刻停止当前进程，转而运行高优先级对列。

#### 内存页面置换算法

缺页异常（缺页中断）

缺页中断在指令执行期间产生和处理中断信号，一般中断在一条指令完成后检查处理

缺页中断返回到该指令的开始重新执行指令，一般中断返回到该指令的下一个指令

CPU一条Load M指令，CPU去找M对应的页表项，如果状态位无效，CPU发送缺页中断给os，os执行缺页中断处理函数，查找页面在磁盘中的页面位置，在物理内存找空闲页，将磁盘中页面换入物理内存，将页表项中的状态位改为有效，CPU重新执行导致缺页异常的指令。

找不到空闲页，则说明内存已满，需要页面置换算法选择一物理页，如果是脏页，换出磁盘，置无效，再把正访问的页面装入物理页中。

最佳页面置换算法（理想）：置换未来最长时间不访问的页面

先进先出置换算法

最近最久未使用的置换算法（LRU）：选最长时间没有被访问的页面进行置换

LRU->历史判断

OPT->未来视

但开销大，需要维护一个所有页面的链表，最近最多放表头，最近最少使用放表尾。而且每次访问内存都要更新整个链表。找页面，删除，放表头，非常费时。

时钟算法CLock，根据访问位，转动，遇到1置零，遇到0淘汰。

最不常用算法LFU

缺页中断时，选择访问次数最少的页面，并淘汰。

### 文件系统

每个文件有两个数据结构：索引节点（index node）和目录项（directory entry），记录文件的元信息和目录层次结构。

inode记录文件元信息，inode编号、文件大小、访问权限、创建时间、修改时间、数据在磁盘位置。是唯一标识，也储存在硬盘。

目录项，dentry，记录文件的名字，索引节点指针和其他目录项的层级关联。目录项由内核维护，缓存在内存。





#### 文件系统

没看太清楚

#### 文件IO

- 缓冲与非缓冲I/O

根据是否利用文件操作的标准库

缓冲利用标准库的缓存实现文件的加速访问，标准库通过sysctl访问文件（换行时才真正输出，换行前被标准库暂时缓存，减少了系统调用次数，减少CPU上下文切换）

非缓冲直接通过系统调用访问文件

- 直接与非直接I/O

是否利用OS的缓存，

直接：不发生内核缓存和用户程序之间的数据复制，直接经过文件系统访问磁盘

非直接：读时，数据从内核缓存拷贝给用户程序，写时，数据从程序拷贝给内核缓存，再由内核决定什么时候写入磁盘

O_DIRECT 直接I/O

- 阻塞与非阻塞I/O vs同步异步I/O

用户程序read，线程阻塞，一直等到内核把数据准备好，并把数据从内核缓冲区拷贝到应用程序缓冲区。

非阻塞区别是，read后，如果数据没准备好，立刻返回，然后轮询内核。

比如访问管道或socket，设置O_NONBLOCK，表示非阻塞

解决比较愚蠢的轮询，出现IO多路复用，select poll。

此上都是同步IO，如果内核拷贝效率不高，read会在这个同步过程等待较长时间。

异步IO，内核准备数据，数据从内核拷贝到用户态，两个过程都不用等待。

aio_read

#### 网络系统

OSI网络模型

应用层：给应用程序提供统一接口

表示层：负责将数据转换成兼容另一系统能识别的格式

会话层：建立、管理和终止表示层实体之间的通信会话

传输层：端到端的数据传输

网络层：数据路由、转发、分片

数据链路层：数据封帧、差错检测、MAC寻址

物理层：物理网络中传输数据帧

TCP/IP 4层

应用层：给用户提供一组应用程序HTTP，DNS，FTP

传输层：TCP、UDP端到端通信

网络层：网络包封装分片路由转发，IP、ICMP

网络接口层：网络包在物理网络中传输

![image-20220317173344187](C:\Users\call1\AppData\Roaming\Typora\typora-user-images\image-20220317173344187.png)

最大传输单元（MTU）1500Bytes

#### IO多路复用

select/poll

select 将已连接socket都放在一个FD集合，然后调用select将FD集合拷贝到内核，让内核检查是否有网络事件，检查方式暴力遍历，有事件之后标记该socket为可读或可写，再将整个FD集合拷贝回用户态，然后用户态再遍历找到可读可写socket。

select遍历2次，拷贝两次FD集合。

select使用固定长度BitsMap表示FD集合，FD_SETSIZE默认最大值1024，监听0-1023号FD

poll不用BitsMap，而用动态数组，链表形式组织。

都是线性结构，O(n)时间复杂度。



epoll

1、内核中用RBT跟踪进程所有待检测FD，epoll_ctl()将监控的socket加入RBT，

2、事件驱动，内核中维护一个链表记录就绪事件，当有事件发生，通过回调函数内核会将其加入就绪事件列表，用户调用epoll_wait()，只返回发生事件的fd个数，不需要遍历整个socket。

epoll有两种事件触发模式

边缘触发（edge-triggered，ET）

当被监控的Socket描述符上有可读事件发生时，服务器端只会从epoll_wait中苏醒一次，即使进程没有从内核中read，也只苏醒一次，因此我们的程序需要保证一次性将内核缓冲区中的数据读完

水平触发（level-triggered，LT）

当被监控的socket上有可读事件时，服务器端会不断epoll_wait()，直到内核缓冲区数据被read函数读完才结束。

边缘触发一般和非阻塞IO搭配，程序一直IO直到sysctl（readorwrite）返回错误，EAGAINorEWOULDBLOCK



#### Reactor 和 Proactor







![img](https://camo.githubusercontent.com/8813be3bb9590eba2207d27b95404ec996891960b47ebb3a447b6c943c0b714d/687474703a2f2f7777312e73696e61696d672e636e2f6c617267652f303035544a3263376c79316765306a3161747135686a33306736306c6d3077342e6a7067)

### wangluo

TCP 流量控制、超时重传、拥塞控制，为了保证数据包能够可靠传输



IP地址：1、网络号，标识该ip地址是属于那个子网的

2、主机号，负责标识同一子网下的不同主机

配合子网掩码可以计算出网络号和主机号，于是寻址时先匹配到相同网络号，才会去找对应主机

IP协议还有个能力是路由，IP寻址告诉我们下个目的地该往哪个方向走（导航），路由根据下一个目的地选择路径（方向盘）。

每台设备的网卡都有一个MAC，用来唯一标识设备。



#### HTTP

what is http？ 超文本传输协议，hyper Text transfer Protocol

用在计算机世界里的协议。使用计算机能理解的语言建立了一种计算机之间交流通信的规范，以及各种控制和错误处理方式。

HTTP是个双向协议。

超文本：超越了普通文本的文本，是文字、图片视频等的混合体，还有超链接，即从一个超文本跳转到另一个超文本。

HTML是常见的超文本。

队头阻塞，服务器按照顺序先回应A请求，之后在后边的，如果前面慢，后边就会排队阻塞。

HTTPS在HTTP和tCP之间加入SSL/TLS安全协议。HTTPS在TCP三次握手后，还要进行SSL/TLS握手过程，然后才能加密报文传输，端口443

混合加密->机密性，防止窃听

摘要算法->完整性，防止篡改

数字证书防止冒充。

#### TLS握手过程

1、Client Hello：TLS版本号、支持的密码套件列表、Client Random

2、Server Hello：TLS版本号、选择的密码套件列表，Server Random

Server Certificate 含有数字证书 + Server Hello Done

#### 数字证书都包括什么

公钥，持有者信息，证书认证机构（CA）信息，CA对这份文件的数字签名及算法，证书有效期，额外

#### HTTPS ECDHE握手

过

#### HTTP/2

通过stream设计，多个stream复用一条TCP，达到并发效果

1个TCP连接包含一个或多个Stream，Stream是HTTP/2并发的关键

Stream中可以包含1个或多个Message，Message对应HTTP/1中的请求或响应

Message中包含一条或多个Frame，Frame是HTTP/2最小单位，二进制压缩存放HTTP/1中的内容。

HTTP/2中，不同Stream帧可乱序发送（并发）

#### 连接

用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括Socket、序列号和窗口大小称为连接。

device 自旋排好，粒子进入和它进行自旋相互作用

发送方Naggle，接收方延迟确认，同时使用会造成额外时延

增大半连接队列，不能只单纯增大tcp_max_syn_backlog的值，还需要一同增大somaxconn和backlog，也就是accept队列。否则单纯增大tcp_max_syn_backlog是无效的



#### IP基本

网络层，实现主机与主机之间的通信，也叫点对点通信

五地址分类CIDR

网络号+主机号

a.b.c.d/x 

/x前x位是网络号

子网掩码划分网络号和主机号形式

#### 题

2022/04/06

字节面试题：25. K 个一组翻转链表 42. 接雨水 23. 合并K个排序链表 41. 缺失的第一个正数 124. 二叉树中的最大路径和 76. 最小覆盖子串 32. 最长有效括号 72. 编辑距离 4. 寻找两个正序数组的中位数 239. 滑动窗口最大值



已投：校招：字节1，腾讯（未知），百度，华为

2022/04/07

早上9:30腾讯IEG就下了面试邀请，但是是今晚七点，有点太早了，所以我申请了换到明天或后天，希望别给我挂了

已挂

[我的投递 | 腾讯音乐娱乐招聘 (tencentmusic.com)](https://join.tencentmusic.com/deliver)

[网易校园招聘 (163.com)](https://campus.163.com/app/personal/apply)

https://game.campus.163.com/

[我的简历| 美团招聘官网 (meituan.com)](https://campus.meituan.com/resume-edit)

[小米公司 - 校园招聘 (mokahr.com)](https://app.mokahr.com/campus-recruitment/xiaomi/47097#/candidateHome/applications)

[miHoYo校招内推 (mokahr.com)](https://app.mokahr.com/recommendation-apply/mihoyo/24513#/)

![img](https://mp.weixin.qq.com/cgi-bin/showqrcode?ticket=gQE07zwAAAAAAAAAAS5odHRwOi8vd2VpeGluLnFxLmNvbS9xLzAyaEhsNlE1Q0thRWUxbnhtdHh5Y0IAAgRhHFRiAwSAOgkA)























hello world

h  e  l  o  w  r  d  space

1  1  3  2  1  1  1  1

1  2   8   7    3  4   5  6frequency

主要爱好的游戏集中在PC与主机游戏中，手游中最近在玩的只有一个休闲类的世界弹射物语，配队自由度很高，并且支持三人共斗，有时会和朋友小玩一下。爱好的主机游戏中，任天堂IP的游戏涉猎较多，如《塞尔达传说旷野之息》（全神庙）、《马力欧奥德赛》（全收集）、《密特罗德生存恐惧》（全收集通关）、《马力欧卡丁车8》（除200cc外全3星，网战打得较少）、《动物森友会》（2020年上半年疫情期玩得时间较多，大约400h）、《塞尔达传说天空之剑》（通关）、《织梦岛》（通关）等，此外switch上的《怪物猎人崛起》、《怪物猎人gu》，ps上的《怪物猎人世界+冰原》游玩时间都在400小时以上，除铳枪与长枪外大多数武器都较熟练；任天堂早期的游戏也有玩过很多，包括nds和3ds平台上的若干游戏。去年ps5国行版刚发布时第一时间购入，体验了很多ps平台的游戏，如《战神》（通关）、《底特律变人》（白金）、《血源》（三周目白金）、《暗影火炬城》（白金）、《AI梦境档案》（白金）、《死亡搁浅》（通关，导剪版还没有时间体验）。PC游戏的游玩渊源更深，小学的时候就有体验过当时很火的网络游戏《梦幻西游》、《地下城与勇士》、以及一众武侠仙侠游戏，但玩的都不是很深入，之后也是单机游戏玩的比较多，如果只说近几年体验过的游戏，国产游戏《戴森球计划》（2021年初通关，一百五十小时左右）算是我个人最爱之一，起初几个人的团队能够做出这样震惊世界的游戏，再加上我的专业是理论物理，更是向往宇宙星辰，当时的体验真是让我激动万分，此外国游中有很多小体量的AVG游戏都很不错，如《烟火》、《全网公敌》等。PC上的“宫崎英高系列游戏”我也大多有体验，如《黑魂1重制》（3周目）、《黑魂3》（3周目）、《只狼》（4周目）、《艾尔登法环》（一周目快通关，最近游戏时间较少），当然还有之前说到ps平台上的《血源》，这类游戏的地图设计与boss设计堪称精品，第一次体验到黑暗之魂1中的地图时，有醍醐灌顶之感，有人将这类游戏的地图设计与3D银河城游戏相比较，确实很有道理，尽管我此前没有玩过3D银河城类游戏，但与我第一次玩到2D银河战士（密特罗德）时为地图设计惊叹有着相似的感受。除了以上说到的，还有很多我体验过的游戏，感觉能说上几天几夜，我确实很喜欢游戏，也曾经很想进入游戏行业，但是目前看国内游戏的生长环境似乎并不是很乐观，总之还是希望中国的游戏业能够继续努力壮大发展下去。







#### priority_queue<>

```c++
template<
    class T,
    class Container = std::vector<T>,
    class Compare = std::less<typename Container::value_type>
> class priority_queue;
```

Container：vector,deque

Compare：默认less<T> operator <

默认大顶堆，当需要pq保存自定义数据类型，需要重载<或写仿函数

```c++
bool operator<(MyType a, MyType b)
{
    if(a.x == b.x) return a.y < b.y;
    return a.x<b.x;
}
priority_queue<MyType> que;
```

```c++
struct cmp//需自定义类
{
    bool operator()(T a, T b)//重载()
    {
    	if(a.x == b.x) return a.y < b.y;
    	return a.x<b.x;
    }
};
priority_queue<T,vector<T>, cmp> que;

```

若要小顶堆，重载<或自定义类cmp

O(lgN)插入，O(1)取得最大最小值

#### HTTP2.0

HTTP/1.1需要优化：请求-响应模型、头部巨大重复、并发连接耗时、服务器不能主动push

1、没有在URI中引入新协议名；2、只做应用层改变将HTTP分解为语义和语法两部分

HTTP/1.1可以用Content-encoding指定body的压缩方式，但header不能

> HPACK算法压缩
>
> - 静态字典：61组，写入HTTP/2框架。index-Headername-Headervalue
>
> header value经过Huffman编码再发
>
> - 动态字典
>
> - 霍夫曼编码
>
>   ![image-20220414234446220](C:\Users\call1\AppData\Roaming\Typora\typora-user-images\image-20220414234446220.png)
>
> 同一HTTP2连接上发送的报文越多，字典积累就会越多，理论上每个头部字段都会变成1字节的index
>
> 然而动态表越大，占用内存越大，http2_max_requests限制一个连接上能传输的请求数目

> 将响应报文分成两个帧（Frame），HEADERS和DATA
>
> HEADERS有9字节，前3bytes标识帧数据长度，之后1B帧类型（数据帧，控制帧），1B标志位
>
> 1bit最高位，31bits流标识符，最大值2^31，标识该frame属于哪个Stream，根据这个信息从乱序帧中找相同StreamID的帧，有序组装信息。
>
> DATA用HPACK算法压缩过的HTTP头和包体

> Stream设计实现了并发传输，多个Stream可以复用一个TCP连接
>
> 1TCP连接-》多个STREAM-》多个Message（HTTP1中请求响应）-》多个Frame（HTTP2的最小单位）
>
> 不同Stream可以乱序，同一Stream中的Frame必须有序
>
> 客户端Stream必须奇数，服务器建立的必须偶数
>
> HTTP2实现100个Stream只需1TCP，HTTP1需要100TCP，每次都要3握手、慢启动、TLS握手

>主动推送
>
>HTTP1.1从服务器获取HTML，HTML依赖CSS渲染页面，这时客户端还会请求CSS
>
>HTTP2可以直接psh，服务器推送时，通过PUSH_PROMISE帧传输HTTP头部，通过帧中的Promised Stream ID告知客户端，接下来会在哪个偶数号Stream中发送包体

其他

> 流控制、流状态、依赖关系，HTTP2仍有TCP层次的队头阻塞问题

#### c++11,14,17

- 数据类型 long long(64bits)

- 列表初始化：用于内置类型的变量时，如果用列表初始化，且初始值存在丢失信息风险，编译器报错（int->double)

- nullptr：特殊类型的字面值，可以转换为任一类型的指针，过去的NULL时预处理变量给指针赋值，定义在cstdlib值是0；建议初始化所有的指针，也避免使用NULL

- constexpr：将新变量声明constexpr便于编译器验证变量的值是否是个常量表达式。声明constexpr的一定是常量，必须用常量表达式初始化

  ```c++
  constexpr int mf = 20;
  constexpr int limit = mf+1;
  constexpr int sz = size();//只有当size也是constexpr函数才是正确声明
  ```

- using别名声明：using SI = Sales_item;等号左边的名字规定为右侧类型的别名

```c++
typedef int (*fun)(int *);   //以前c++的做法，声明一个参数为`int *`，返回值为int的函数指针，名字叫fun
using fun = int (*)(int *);  //c++11，这样更加直观
 
template <typename T>
using newType = std::pair<T, T>;
```



- auto：编译器分析表达式所属类型。通过初始值推算变量类型，必须有初始值因此。

- decltype：希望从表达式类型推断要定义的变量类型，而不想用该表达式的值初始化变量。

  decltype(f()) sum = x;

  ![image-20220415012400714](C:\Users\call1\AppData\Roaming\Typora\typora-user-images\image-20220415012400714.png)

  decltype(())双层括号的结果永远是引用

- 类内初始值

- 范围for

- vector的vector

```
vector<vector<int> >//过去
vector<vector<int> //c++11
```

- vector列表初始化

```
vector<string> articles = {"a","an","the"};
vector<int> n{1,2,3};//正确
vector<int> n1(1,2,3);//错误
```

- cbegin,cend ：只需读const_iterator
- 标准库函数begin，end

```
int ia[] = {0,1,2,3};
int *beg = begin(ia);
int *last = end(ia);
```

- 除法：C++早期允许结果为负值的商向上或向下取整，11规定商一律向0取证，即直接切除小数部分。
- sizeof用于类成员
- initializer_list类of标准库：不同数量的实参，initializer_list可变参数数量。
- 列表初始化返回值：return{1,2,3};
- 尾置返回类型：auto func(int i) -> int(*)[10];通常用于返回类型较复杂的fun
- decltype返回类型
- =default：默认构造函数；=delete禁用默认函数
- array+forward_list
- swap的非成员函数版本
- insert返回插入后的第一个新加入元素的迭代器
- emplace：将参数直接传递给元素类型的构造函数，直接构造
- lambda
- override：显式控制虚函数重载，final显式终结类的继承和虚函数的重载使用
- 

#### JSON WEB TOKEN

跨域认证解决方案。定义了一种紧凑的、自包含的方式、用于作为JSON对象再各方之间安全传输信息。

> 什么时候用：
>
> Authorization(授权)：一旦用户登录，后续每个请求都将包含JWT，允许用户访问该令牌允许的路由、服务和资源。
>
> Information Exchange：JWT可以被签名，如用公钥/私钥对，可以确定发送人是那个人。签名有头和有效负载计算，可以验证内容是否被篡改。

>结构：
>
>- Header：token类型("JWT")和算法名称（HMACSHA256、RSA）
>
>{	’alg‘: "HS256", 'typ': "JWT"  }，然后base64对这个JSON编码
>
>- Payload：声明，关于实体（用户）和其他数据的声明。registered, public, private
>
>Registered claims: 有预定义：
>
>- iss (issuer)：签发人
>- exp (expiration time)：过期时间
>- sub (subject)：主题
>- aud (audience)：受众
>- nbf (Not Before)：生效时间
>- iat (Issued At)：签发时间
>- jti (JWT ID)：编号
>
>Public claims: 随意定义
>
>Private claims: 用于同意使用它们的各方之间共享信息，并不是registered和public的
>
>{"sub ": '1124125' , "name" : 'john', "admin" : true}
>
>- Signature
>
>对前两项的签名，防止数据篡改
>
>xxxx.yyyy.zzzz



>基于服务器的身份认证
>
>HTTP协议无状态，如果认证了一个用户，这个用户下一次请求时服务器不知道是谁，必须再次认证
>
>传统方式是将认证用户信息储存在服务器上，如Session，下次用户请求带上SessionId，然后server检查是否认证过
>
>缺点：用户多，开销大；扩展性不好，因为Session在内存；



>JWT储存在客户端，减轻服务器端的内存压力
>
>基于token的身份认证是无状态的，服务器不会储存用户信息。
>
>没有信息意味着可以扩展或添加机器，不担心用户登录位置
>
>过程：用户名+密码请求访问--》服务器校验用户凭据--》应用提供一个token给客户端--》哭护短储存token，后续每一次请求中都携带--》服务器校验token并返回数据
>
>客户端收到的jwt可以储存在Cookie或者localStorage，放在Cookie中无法跨域
>
>最好是放在HTTP头，Authorization: Bearer <token>
>
>token放在请求Header中，服务器设置接受来自所有域的请求：Access-Control-Allow-Origin: *

![img](https://pic1.zhimg.com/80/v2-7789057d5744891fdf3366d7887ab6e8_1440w.jpg)

好处：无状态和可扩展星。负载均衡器可以将用户请求传递到任一服务器，在任何地方都没有状态和会话。

安全：token不是cookie，防止CSRF攻击。

缺点：一旦签发JWT，在到期之前就会始终有效，除非服务器有额外逻辑；包含认证信息，一旦泄露，任何人都可以获得该令牌的所有权限。因此有效期应该足够短。重要权限使用时应对用户再次认证。

#### URL输入到网页出现

1、浏览器根据请求的URL交给DNS域名解析，找到真实IP，向服务器发起请求

2、服务器交给后台处理完成后的返回文件，浏览器接收文件（HTML、JS、CSS、图像）

3、浏览器对加载到的资源进行语法解析，建立相应的内部数据结构（HTML的DOM）

4、载入解析到的资源文件，渲染页面。



1、浏览器地址栏输入URL

2、浏览器查看缓存，如果请求资源在缓存中且未过有效期，跳转到转码步骤

​	如果为缓存，发起新请求

​	如果已缓存，检查是否新鲜，足够新鲜直接提供给客户端，否则与服务器进行验证

​	检查新鲜：两个HTTP头：Expires 、Cache-Control

​		HTTP1.0 Expires：绝对时间表示缓存新鲜时间

​		HTTP1.1 Cache-Control：max-age = time 以秒为单位的最大新鲜时间

3、浏览器解析URL获取协议，主机，端口，path

4、浏览器组装一个HTTP（GET）请求报文

5、浏览器获取主机ip地址

​		浏览器缓存->本机缓存->hosts文件->路由器缓存->ISP DNS缓存->DNS递归查询（负载均衡条件下每次ip可能不同）

6、打开一个socket与目标ipport建立TCP连接，3次握手

​		客户端发送TCP，SYN = 1，Seq = x

​		服务端发回TCP，SYN = 1，ACK = x+1，Seq = y

​		客户端发送，ACK = y+1，Seq = Z（x+length）

7、TCP连接后发送HTTP请求（TLS4次）

8、服务器接收请求解析，将请求转发到服务程序

9、检查HTTP请求头是否包含缓存验证信息，如果缓存验证新鲜，发送304等对应状态

10、处理程序读取完整请求准备HTTP响应，可能需要查询数据库等操作

11、服务端通过TCP连接将响应报文发回浏览器

12、浏览器接收到HTTP响应，可以选择关闭TCP连接或者保留重用，关闭TCP

​		主动方 Fin = 1、Ack = Z，Seq = X

​		被动方发 Ack = X+1、Seq = Z

​		被动方发送Fin = 1、Ack = X、Seq = Y

​		主动方发 Ack = Y、Seq = X

13、浏览器检查响应状态码：1xx，3xx，4xx，5xx

14、如果资源可缓存，进行缓存

15、对响应解码（如gzip

16、根据资源类型决定如何处理

17、解析HTML⽂档，构件DOM树，下载资源，构造CSSOM树，执⾏js脚本，这些操作没有严 格的先后顺序，以下分别解释：

（后边的不会

16、构建DOM树：

Tokenizing：根据HTML规范将字符流解析为标记

Lexing：词法分析将标记转换为对象并定义属性和规则

DOM construction：根据HTML标记关系将对象组成DOM树

17、解析过程中遇到图⽚、样式表、js⽂件，启动下载

18、构建CSSOM树：

Tokenizing：字符流转换为标记流

Node：根据标记创建节点

CSSOM：节点创建CSSOM树

19、根据DOM树和CSSOM树构建渲染树 :

从DOM树的根节点遍历所有可⻅节点，不可⻅节点包括：

script , meta 这样本身 不可⻅的标签。
被css隐藏的节点，如 display: none
对每⼀个可⻅节点，找到恰当的CSSOM规则并应⽤

发布可视节点的内容和计算样式

20、js解析如下：

浏览器创建Document对象并解析HTML，将解析到的元素和⽂本节点添加到⽂档中，此时**document.readystate为loading**

HTML解析器遇到没有async和defer的script时，将他们添加到⽂档中，然后执⾏⾏内 或外部脚本。这些脚本会同步执⾏，并且在脚本下载和执⾏时解析器会暂停。这样就可以⽤document.write()把⽂本插⼊到输⼊流中。同步脚本经常简单定义函数和注册事件处理程序，他们可以遍历和操作script和他们之前的⽂档内容

当解析器遇到设置了async属性的script时，开始下载脚本并继续解析⽂档。脚本会在它 下载完成后尽快执⾏，但是解析器不会停下来等它下载。异步脚本禁止使⽤ document.write()，它们可以访问⾃⼰script和之前的⽂档元素

当⽂档完成解析，document.readState变成interactive

所有defer脚本会按照在⽂档出现的顺序执⾏，延迟脚本能访问完整⽂档树，禁止使⽤ document.write()

浏览器在Document对象上触发DOMContentLoaded事件

此时⽂档完全解析完成，浏览器可能还在等待如图⽚等内容加载，等这些内容完成载⼊ 并且所有异步脚本完成载⼊和执⾏，document.readState变为complete，window触发 load事件

21、显示⻚⾯（HTML解析过程中会逐步显示⻚⾯）
————————————————
版权声明：本文为CSDN博主「七钥」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/Newbie___/article/details/107212575

#### RBTree

特征：1，节点是红黑；2，根是黑色；3，所有叶子节点都是黑色（NIL）；4，每个红色节点必须有两个黑色子节点（从每个叶子到根的所有路径上不能有两个连续的红色节点）；5，任一节点到其每个叶子节点的所有简单路径都包含相同数目的黑色节点。

调整：1，变色；2，左旋；3，右旋；

红黑树深度较大，B树B+树深度较小；B+树将数据都保存在叶子节点，同时通过链表连接一起。

红黑树是一种平衡二叉查找树。它是为了解决普通二叉查找树在数据更新的过程中复杂度退化的问题而产生的。红黑树的高度近似 log2n，所以它是近似平衡，插入、删除、查找操作的时间复杂度都是 O(logn)。因为红黑树是一种性能非常稳定的二叉查找树，所以，在工程中，但凡是用到动态插入、删除、查找数据的场景，都可以用到它。不过，它实现起来比较复杂，自己写代码实现，难度会有些高，这个时候，我们其实更倾向用跳表来替代它，跳表的源码我都看了好几遍了，要不，我给你讲讲跳表。



#### B B+

大部分文件系统，数据库系统都采用BB+树作为索引结构

B+只有叶子节点带指向记录的指针，B树所有节点都带，内部节点出现的索引项不会出现在叶子。

B+优点：非叶子节点不带ROWID，一个块中可以容纳更多索引项，降低树高度，内部节点可以定位更多叶子节点。叶子节点指针连接，可范围扫描。B树需要在叶子节点和内部节点间不停往返移动。

#### Log线程

#### SSL

> RSA密钥交换算法实现的TLS握手
>
> TLS证书部署在服务器端，证书文件有一对公钥私钥，公钥在TLS握手阶段传给客户，确保私钥在服务端不被窃取。
>
> 客户端生成随机密钥，通过服务器端传来的公钥加密传给服务端。根据非对称加密算法，公钥加密的消息仅能通过私钥解密，这样服务器端解密后，双方就得到相同的密钥，之后用它加密消息。
>
> 通常是4次握手
>
> 1、Client Hello：TLS版本，支持的密码套件、Client Random
>
> 2、Server Hello：TLS版本，Server Random，选择的密码套件
>
> Cipher Suite: TLS_RSA_WITH_AES_128_GCM_SHA256
>
> 密钥交换算法+签名算法+对称加密算法+摘要算法
>
> RSA、RSA(WITH)，AES对称算法（密钥长度128位、分组模式GCM）；SHA256摘要算法用于消息认真和产生随机数
>
> 2个Random是生成会话密钥（对称加密）的条件。
>
> Server Certificate：数字证书
>
> Server Hello Done：打招呼完毕
>
> CA？
>
> 3、CLient验证完证书，生成随机数（pre-master），用RSA公钥加密，通过Change Cipher Key Exchange发送，双端共享了3个随机数，Client Random、Server Random、pre-master
>
> 根据3随机数生成Master Secret，对称密钥
>
> 生成完，客户发Change Cipher Spec，告诉服务端开始用加密方式通信。
>
> 再发Encrypted Handshake Message（Finished），将之前所有发送的数据做摘要，用会话密钥加密，让服务器验证是否被中途篡改
>
> 4、同样操作like3，发Change Cipher Spec，Encrypted Handshake Message

缺点：不支持前向加密

>  DH密钥协商算法
>
> 客户端发Hello，服务端生成公私钥，发给客户公钥，客户端也生成公私钥，发给服务端公钥。客户端有客户私和服务公，服务端有服务私和客户公，双方都算出一个密钥，应当相同，后续通信用这个密钥。
>
> 计算效率有问题

> ECDHE密钥协商算法
>
> 相比RSA协商的第2、3次握手，多了Server Key Exchange和Client Key Exchange
>
> Server Key Exchange：选名为name_curve的椭圆曲线（基点G），公开给客户端；生成Random作为私钥存放本地；根据G和私钥计算服务端的椭圆曲线公钥，公开给客户端。保证不被第三方篡改，服务端用RSA签名算法给公钥签名。
>
> Client Key Exchange：双方计算点（x,y)，其中x坐标双方相同，
>
> 最终会话密钥：Client Random + Server Random + x
>
> 

CA

认证公钥持有者身份，防止第三方进行冒充。用来告诉客户端，该服务端是否是合法的，只有证书合法，才代表服务端身份可信。

#### 时间轮

升序链表：添加定时器O(n)，删除定时器O(1)，执行定时任务O(1)，alarm函数周期性的触发SIGALRM信号，该信号的信号处理函数通过管道通知主循环执行定时器链表上的定时任务，关闭非活动链接。epoll_wait返回0表示超时时间到，可以处理定时任务，并重置定时时间

时间轮：

基于升序链表的问题，添加定时器的效率低。

![image-20220415142102371](C:\Users\call1\AppData\Roaming\Typora\typora-user-images\image-20220415142102371.png)

实线指针指向轮子的一个槽slot，恒定速度顺时针转动，转动一步指向下一个slot，每次转动为1tick，一个tick的时间为槽间距si（slot interval），转一周是N*si。每个槽都对应一条定时器链表，其上定时器的定时时间相差N\* si的整数倍，以此散列在不同链表上。

现在在cs槽，添加一个定时时间为ti的定时器，则该定时器被插入槽ts(timer slot)对应链表中：
$$
ts = (cs+(ti/si)) \% N
$$
用到了hash的思想，要提高定时精度，需要使si足够小；提高效率，需要N足够大。复杂时间轮可能有多个轮子，不同轮子有不同粒度。相邻轮子，精度高转1圈，精度低转1槽。

时间轮：添加定时器O(1)，删除定时器O(1)，执行一个定时器O(n)，但实际上会更好，槽越多越好，散列表的入口越多，而且当使用多个轮子，执行一个定时器任务的时间复杂度将接近O(1)



时间堆

将所有定时器中超时时间最小的一个定时器的超时值作为心搏间隔，一旦tick调用，则超时时间最小的定时器必然到期，tick函数处理定时器，然后再次从剩余的定时器中找到超时时间最小的，并将这段最小时间设定为下一次间隔。

小根堆，每个节点都小于等于其子节点的值的完全二叉树。对于位置i的节点，左孩子2i+1，右孩子2i+2，父节点（i-1)/2（i>0），开始对（N-1）/2-0个元素下滤，对于N个元素的完全2，有（N-1）/2个非叶子节点。需要保证所有非叶子有堆序结构，则整体有堆序结构。添加定时器O(lgn),删除O(1)，执行O(1)。

#### 保持登录

cookie+session和token

HTTP无状态

cookie+session：服务端登陆时，分配一个session用于储存数据，同时将sessionid返回给浏览器

浏览器通过cookie将sessionid保存，下一次访问时携带上

服务端可以通过sessionid确定用户是否已登录。

缺点：服务端内存，不支持cookie，集群->集群+session持久化，session共享，每一台服务器都共享所有用户信息

TOKEN

登陆时，服务器根据用户名签发token，服务端不保存，下一次访问带上token，服务器校验token

优势：token无状态、集群访问、性能比查询数据库块、跨站点、移动端



#### 异步同步阻塞非阻塞

同步：发出一个功能调用时，在没得到结果之前，这个调用不返回或继续执行后续操作。事情要一件一件做，前一件做完才能做下一件事。

异步：一个异步过程调用发出，调用者在没得到结果之前，可以继续执行后续操作。当调用完成，通过状态、通知、回调通知调用者。异步调用中，调用的返回不受调用者控制。

​	状态：监听被调用者状态（轮询），调用者每隔一段时间检查一次，效率低。

​	通知：被调用者执行完成，发出通知告知调用者，消耗性能低。

​	回调：调用者完成后，调用调用者提供的callback

同步与异步区别：请求发出，是否需要等待结果才能继续执行操作。



阻塞非阻塞

与程序（线程）等待==消息通知时的状态==有关，关注等待调用结果时（消息，返回值）的状态。

阻塞调用指调用结果返回之前，当前线程挂起，调用线程只有在得到结果后才会返回。

非阻塞调用指不能立刻得到结果之前，该调用不会阻塞当前进程。

看

同步异步关注消息通知机制，阻塞非阻塞关注程序等待消息通知时的状态。







#### 如何实现抓取HTTPS加密报文并解密

wireshark ssl



### LRU

LRU介绍，底层数据结构，高并发情况下如何设计LRU



#### 线程池



#### 一次查询几十万条数据如何优化？（项目？）



#### 多态

#### left join、inner join、right join

左联接，返回包括左表中的所有记录和右表中连结字段相等的记录

等值连接，只返回两个表中连接字段相等的行

#### 排序算法介绍，复杂度比较，是否稳定

O(N^2)：冒泡（稳定），选择（数据不稳定，链表稳定），插入（稳定）

O(nlogn)：快排（最差O(n^2)不稳定），堆排序（不稳定)，归并稳定，希尔不稳定

O(n)：计数排序，桶排序，基数排序

#### DNS解析过程，给个URL一层一层具体分析

#### HTTP状态码

#### unordered_map和map的区别

#### IPC的几种方式？

#### MySQL的连接池怎么实现的MySQL默认/最大支持连接数是多少？

#### 

- MySQL索引都有哪些？

MySQL的主从复制

常见的路由选择算法能说一下吗？

进程通信方式，哪个最快，哪个不受信号量的限制

AES 知道吗，原理是什么？作用是什么

网络通信中滑动窗口的原理，作用。
慢启动算法了解吗？
堆和栈的区别和应用场景。
页式结构的好处。

TCP报文段的结构，各部分的作用。
拥塞控制的过程和节点

100亿无符号整数，求最大的前100个，你的内存无限大

3.CAP什么意思？

ca证书的作用

跳表

平时是在 linux 下开发吗？

怎么统计 tcp 连接数？

怎么查看内存使用情况？

怎么根据 pid 获取对应的程序名？

知道怎么在 linux 调整进程优先级吗？（这个真不会）

CA证书是什么，上面有啥内容，用户怎么验证（有点忘了，麻）
DDOS攻击是怎么样的，服务器端第三次握手会持续到什么时候





### After4.15BD1

todo：

#### 智能指针，引用怎么做的

静态内存存局部static对象、类static数据成员、定义在所以函数之外的的变量。

栈内存存函数内的非static对象。

静态内存和栈内存中的对象由编译器自动创建和销毁。

shared_ptr允许多个指针指向同一对象，unique_ptr独占所指向对象。weak_ptr伴随类，弱引用指向shared_ptr所引用的对象。都在memory头文件内

```c++
shared_ptr<string> p1;
shared_ptr<list<int>> p2;
```

动态内存管理：1、忘记delete，内存泄漏

2、使用已经释放掉的内存，空指针

3、同一块内存释放两次，可能破坏自由空间

不能将一个内置指针隐式转换为一个智能指针，必须使用直接初始化形式来初始化一个智能指针。

不要用get初始化另一个智能指针或者为另一个智能指针赋值，会导致两个智能指针的use_count 都是1，

另一个智能指针作用域过去后，会释放get得到指针对应的空间，导致原智能指针空悬





```c++
shared_ptr<int> sp(new int[10],[](int *p){delete [] p;});
sp.reset();
```

shared_ptr未定义下彪运算符，且不支持指针算数运算，为了访问数组中的元素，必须用get得到内置指针，然后用它访问数组元素。

#### 内核栈作用



#### c++20协程

[c++20协程入门 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/59178345)

协程的出现主要是为了解决异步编程的麻烦，异步编程

````
async_call(input1,input2,...,call_back)
````

输入参数+回调函数，async_call调用后立即返回，异步操作完成时，callback会被调用

对于异步调用，都可以用协程改造成一个如下格式的“同步”调用：

```
co_await coro_call(input1,input2,...)
```

Promise和Awaitable接口15个以上，其中8个(5个Promise的函数和3个Awaitable)是最简单实现

Awaitable：

1、await_ready：返回Awaitable实例是否已经ready。协程开始会调用这个函数，如果true，表明结果已经得到，协程无需执行。大部分这个函数要返回false

2、await_suspend：挂起awaitiable。。。。。。。。。。。





**协程是一种函数对象，可以设置锚点做暂停，然后再该锚点恢复继续运行**

轻量级线程？协程有中断可恢复的特性，只需要开一个全局数组，储存所有协程，当协程中断，不断轮转调用下一个协程继续执行即可；协程本质上是函数，调用协程后原来的地方会被阻塞，协程处理完才会返回结果，天然同步。对于线程，调度受内核控制，触发点来自硬件时钟，又运行在多核，调用次序不确定。协程函数，天然同步，遇到阻塞，把CPU让给别的协程，条件满足了再通过中断可恢复特性继续运行，就实现了并发，同步+并发，范式和轮转+同步非阻塞很像。

source是pull_type时，协程直接运行，push_type时，需要传入一个没用的数据启动

fiber（纤程），协程调度器及barrier mutex channel promise future condition_variable sleep yield



#### vector容量增长，pop_back()为什么不能返回值，和析构函数有关？

又一个隐蔽的优化。当vector的存储容量需要增长时，通常会重新申请一块内存，并把原来的内容一个个复制过去并删除。对，复制并删除，改用移动就够了。对于像vector<string>这样的容器，如果频繁插入造成存储容量不可避免的增长时，移动语义可以带来悄无声息而且美好的优化。

#### 重要寄存器

![image-20220419213106943](C:\Users\call1\AppData\Roaming\Typora\typora-user-images\image-20220419213106943.png)



#### 调用函数过程

#### gdb命令

#### 段页内存好处

#### unordered_map、map越细越好

#### malloc怎么实现

```c
void * malloc ( size_t size );
```



#### glibc

#### RAII

#### RTTI

#### move、右值

int &&rr3 = std::move(rr1);： 有个左值，但希望像一个右值一样处理它，承诺除了对rr1赋值或者销毁外，将不再使用。

```c++
template <typename T>
typename remove_reference<T>::type&& move(T&& t)
{
    return static_cast<typename remove_reference<T>::type&&>(t);
}
```

```
string s1("hi!"),s2;
s2 = std::move(string("bye!"));//从一个右值移动数据
s2 = std::move(s1);//赋值后，s1的值是不确定的
```

1、推断T类型为string，remove_reference用string进行实例化，remove_reference<string>的type是string，返回类型是string&&，move的函数参数t是string&&：string&& move(string&&)

2、推断T类型为string&，remove_reference用string&实例化，type是string，move返回类型仍是string&&，t实例化为string& &&，折叠成string&：string&& move(string&)

不能隐式地将一个左值转换为右值引用，但可以static_cast显式将左值转换为一个右值引用

std::forward<Type> (t1)可实现完美转发

####  hash冲突

> hash将任意长度的输入，通过散列算法，变成固定长度的输出，输出结果时散列值，时压缩映射
>
> 冲突：f(key)，发现这个算出的地址已经有人先来了
>
> 1）开放定址（再散列法）
>
> 当p = H(key)出现冲突，以p为基础，再产生另一个hash地址p1，如果p1还冲突，通过p找p2，知道不冲突的pi.
>
> Hi = (H(key) + di) % m (i = 1,2,...,n)
>
> di为增量序列，m为表长。再散列方式主要有3种
>
> > 线性探测再散列
> >
> > dii = 1,2,3,...,m-1
> >
> > 冲突发生，顺序查找表中下一单元，知道找到一个空单元或者查遍全表。
>
> >二次探测再散列
> >
> >di = 12,-12,22,-22,...,k2,-k2 (k <= m/2)
> >
> >冲突发生，在表左右进行跳跃式探测
>
> >伪随机探测再散列
> >
> >di = 伪随机数序列
> >
> >建立一个伪随机数发生器，如（i = (i+p) % m），给定一个随机数为起点。
>
> >如，哈希表长度m = 11， H(key) = key % 11，H(47) =3, H(26) = 4, H(60) = 5,H(69) = 3冲突：
> >
> >线性探测：下一个是H1 = (3+1)%11 = 4，H2 = (3+2)%11 = 5, H3 = (3+3)%11 = 6
> >
> >二次探测：H1 = (3+12)%11 = 4, H2 = (3-12)%11 = 2
> >
> >伪随机：2，5，9... H1 = (3+2)%11 = 5, H2 = (3+5)%11 = 8
>
> 2）再哈希
>
> 同时构造多个不同的hashfunction
>
> Hi = RHi(key) i = 1,2...k
>
> RH1(key)冲突，用RH2...，不易聚集，但计算时间长
>
> 3）链地址法
>
> 将左右哈希地址为i的元素构成一个称为“同义词链”的单链表，将单链表的头指针存在哈希表第i个单元，查找、插入、删除主要在同义词链中能够进行。用于经常插入 删除的情况。
>
> 4）建立公共溢出区
>
> 将哈希表分为基本表和溢出表，凡是和基本表冲突的元素，放入溢出表
>
> 优缺：开放散列表（open hashing）：优点：![image-20220419161434727](C:\Users\call1\AppData\Roaming\Typora\typora-user-images\image-20220419161434727.png)
>
> ![image-20220419161451653](C:\Users\call1\AppData\Roaming\Typora\typora-user-images\image-20220419161451653.png)

#### docker 原理

#### socket 结构

![image-20220419221426477](C:\Users\call1\AppData\Roaming\Typora\typora-user-images\image-20220419221426477.png)

20220421我也被发感谢信了，现在还剩个网易游戏研发的面试

![image-20220421114950079](C:\Users\call1\AppData\Roaming\Typora\typora-user-images\image-20220421114950079.png)

![image-20220421114957411](C:\Users\call1\AppData\Roaming\Typora\typora-user-images\image-20220421114957411.png)

![image-20220421115022659](C:\Users\call1\AppData\Roaming\Typora\typora-user-images\image-20220421115022659.png)

![image-20220421115030687](C:\Users\call1\AppData\Roaming\Typora\typora-user-images\image-20220421115030687.png)

面经

4.17笔试，4.19通知面试

0.5h代码+1h业务 游戏研发岗

项目一句都没问🥹估计要凉

1、写[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法)0.5h

两个有序数组，找两个数组合并起来的有序数组的中位数。（一着急没想起来[二分查找](https://www.nowcoder.com/jump/super-jump/word?word=二分查找)🥹

2、自我介绍

3、满[二叉树](https://www.nowcoder.com/jump/super-jump/word?word=二叉树)的结点个数，叶子结点个数

k层(0开始)的 2\^(k+1)-1个节点，叶子节点2\^k个节点

4、分析代码问题

面试官写了一段代码找问题

static char *p[]="123"；

void func｛

char s[]="abc"；//又改成char *s="abc"；分析语法问题

p=s；

｝

int main(){

func();

}

![image-20220421221149843](C:\Users\call1\AppData\Roaming\Typora\typora-user-images\image-20220421221149843.png)

5、new和malloc

new在自由储存区上为对象动态分配内存，malloc函数在堆上动态分配

自由储存区是C++基于new的一个抽象概念，只要通过new都是自由储存区。堆是操作系统的术语，是操作系统维护的特殊内存。自由储存区在哪取决于operator new的实现

甚至new可以不分配内存，new (place_address) type

void* operator new(size_t, void*);



6、如果new和free一起使用会出现什么问题

不调析构，应该用delete



7、什么是内存碎片，举个例子什么情况出现内存碎片

8、动态编译和静态编译（其实就是动态链接和静态链接，面试官说他们习惯说编译😮‍💨）

9、系统调用和库调用区别

10、进程和线程区别

11、进程间是怎么通信的，除了用共享变量条件变量还有别的方式吗？（我又说了个进程池🌚不知道自己在说啥操作系统还要学🥹

12、多线程之间怎么通信

13、网络编程有了解吗？写网络相关代码要先做啥？

14、http劫持和dns劫持

15、一个网络服务器，能支撑的最大链接数由什么限制

16、端口号划分

17、用过哪些数据库，介绍一下

18、一个交易系统卖无差别物品，买家只买最便宜的物品，卖家可以删除，放入，调整价格，取出操作，用什么数据结构实现？（优先队列，堆

19、口算题不能用纸笔：三个空啤酒瓶可以换一瓶啤酒，现有29瓶啤酒。最后可以喝几瓶？

20、一个5L杯子一个7L杯子，杯子的操作只能是装满水，互倒，倒空（不存在倒半杯水）没有第三个杯子，怎么获得6的水？

21、反问

![img](https://images0.cnblogs.com/i/569008/201405/270929306664122.jpg)







网易互娱2

作者：懂的人都明白
链接：https://www.nowcoder.com/discuss/941402?type=post&order=create&pos=&page=1&ncTraceId=&channel=-1&source_id=search_post_nctrack
来源：牛客网

[网易互娱]()[游戏研发工程师]()一面

 面试前[算法题]()： LC 1151 滑动窗口

 简单问了问项目 

 [c++]()11 新特性 不了解 写Java的
 [c++]() 四种cast
 [c++]() 共享指针
 和c的区别 
 new/malloc new的本质是什么？operator，可以重载 
 [c++]() 内存模型 堆栈 text/bss/data段 堆和栈的区别 堆和栈是用什么数据结构存储的
 stl map unordered_map 用Java手写一个简单的vector 实现拷贝构造函数 
 [红黑树]()详细操作 只知道大概的 为什么要用[红黑树]() 和普通二叉搜索树以及AVL树对比
 http和https的区别 https的加密方法、证书 
 图形学？ 不太了解 

 面试中[算法题]()： LC 42 dp数组 能不能再优化？可以，优化到O(1)空间复杂度 但还是两遍遍历 面试官补充还可以一遍遍历，双指针，时间复杂度O(n)，空间O(1)



  开放问题： 判断敌人受不受一个圆形AOE技能的影响？ 只答出来了暴力求解 面试官补充可以用AOI解决 





////

作者：牛客691251791号
链接：https://www.nowcoder.com/discuss/939776?type=post&order=create&pos=&page=1&ncTraceId=&channel=-1&source_id=search_post_nctrack
来源：牛客网



2022.04.22 

 爬虫是那scrapy库写的吗？ 

-  requests,bs4库等 

 GIL锁 

-  面试官： 
  -  其他一些编程语言的多线程能达到CPU超100%的利用率 
  -  但python因为GIL锁的存在无法超过 

 进程线程协程以及联系 

-  协程：generator，yield 

 [链表]()和数组 

 [哈希表]() 

-  哈希冲突解决方法 
  -  线性探测 
  -  链地址法 
    -  [链表]()改成BST改良查询效率 
    -  改良成数组 

 内核态与用户态 

 RustSBI的项目 

-  你这个有什么功能 
  -  给操作系统提供设备树 
  -  检查硬件设备是否可用 
  -  初始化pmp之类的（类似于全部写入0） 
  -  提供syscall 
-  操作系统要实现哪些功能? 
  -  文件系统 
  -  内存管理 
  -  trap_handle 
  -  IO设备管理 
  -  进程调度 

 知道哪些操作系统 

-  centos 
-  ubuntu 
-  arch 
-  keli 
-  windows 

 查看linux下进程的命令 

-  ps 
  -  有哪些参数？ ----- 忘了 

 mysql 

-  back_log 
-  explain 

 你知道哪些数据库 

-  mysql 
-  [redis]() 
-  tidb 

 TCP和UDP的区别 

 有没有基于UDP的稳定连接 

-  QUIC 

 三次握手，四次挥手时，客户端和服务端的状态变化（SYN_SENT,SYN_RECV之类的） 

 场景题 

 一百万个高考考生成绩，怎么[排序]() 

 coding 

 [数组中出现次数超过一半的数字]()（口头答的，没写） 

-  法1：用栈，遍历，要存入的数据与栈顶数据不同，就把栈顶弹出且不存此数据，相同就放入栈内 
-  法2：统计所有出现数字的频率 

 爬楼梯 

-  先用数组存了dp 
  -  再优化成两个变量 
-  面试官问题：如果你的楼梯数一千或更大，你如何处理，数据过大的问题 

 你老家是哪的（和面试官2居然是一个市的） 

 你的优缺点 



作者：牛客283913382号
链接：https://www.nowcoder.com/discuss/939304?type=post&order=create&pos=&page=0&ncTraceId=&channel=-1&source_id=search_post_nctrack
来源：牛客网



4.17 机试做了1.7个，最后一个迷宫搜索题没调出来 

 4.22 一面（基本凉）

 1.手撕代码 一个球从起点出发 撞到墙才会改变方向，没看对题目写成了普通的迷宫问题，虽然写得不对，面试官还是让讲了思路。

 2.广度优先搜索和深度优先搜索

 说了可以用队列和stack

 3.面向对象的特点 为什么要面向对象

 答得很乱，为什么要用面向对象面试官说是符合人类的直觉。

 4.友元函数

 让我写了个例子（感觉面试官察觉到我是突击的了）

 4.进程和线程

 分配资源的单位；cpu调度的单位。说了下线程调度开销小

 5.多态怎么实现（虚函数表） 构造函数可以是虚函数吗 析够函数呢

 6.多态的条件

 说了子类要重载父类的虚函数，没说到父类指针要指向子类对象，面试官又让我写个例子。写了大概，但是运行不起来（基本写对的，继承写成了::），感觉到面试官的无奈。

 7.智能指针

 说了共享指针 unique指针 ,问我weak指针知道吗，说不知道。

 8.stl了解吗（vector和map）,说下map

 说了键值对存储，[红黑树]()，以及查找效率

 9.unordered_map的实现（hash） hash碰撞怎么解决

 说了线性再探测，还有冲突的放[链表]()（不知道具体是什么方法）

 10.tcp三次握手 为什么要三次握手

 \11. 说下快排

 说了效率平均是nlogn，最坏是n2。

 思想:每次选开头的元素，一趟[排序]()后确定这个开头元素的位置，然后递归处理两边。讲得不好，面试官觉得没说仔细，我都想直接敲了。

 12.讲下项目 textRank

 13.面试官问我有什么问题吗 

 问我是第一次面试表现怎么样，面试官说这个现在不能说，通过面试我应该知道自己的不足。

 感觉凉了，虽然感觉面试官挺和善的，没问什么刁钻问题，但是自己表现很差，八股文背了两天也背得不熟，还暴露了自己[c++]()编程基础不扎实。不过有了第一次面试经验也好，秋招加油!







作者：Moson864
链接：https://www.nowcoder.com/discuss/940739?type=post&order=create&pos=&page=1&ncTraceId=&channel=-1&source_id=search_post_nctrack&gio_id=6FCC68A1316E99662FB0379908324653-1651757194192
来源：牛客网



先笔试0.5小时再面试1小时，消耗真的大，容我干饭先 🙃 

  


  笔试题：
 删除树节点（拓扑[排序]()/DFS）
 给一课以节点0为根节点的树，节点总数nodes个，第i个节点的值为value[i]，第i个节点的父节点是parent[i]，请你删除节点值之和为0的每一棵子树。
 在完成所有删除后，返回树中剩余节点的书目。

 C++：
 \1. Cpp的三大特性，你对他们的理解是什么
 \2. explicit关键字的作用是什么
 \3. 构造函数有哪几种
 \4. 拷贝构造函数为什么输入参数一般是常量
 \5. new和malloc有什么区别（答得是基本作用和释放时候的区别）
 \6. 为什么我们要用到虚析构
 \7. 内存对齐指的是什么（不知道）
 \8. map是用什么实现的？
 \9. stl里有用哈希实现的容器嘛
 \10. stl 的容器线程安全吗
 \11. 你了解哪些智能指针？讲讲理解
 \12. 左值和右值的区别是什么
 \13. 你了解快速[排序]()吗，快速[排序]()最坏时间复杂度是多少，如何优化最坏的情况？
 \14. 哈希在插入元素的时候时间复杂度是多少？
 \15. 哈希函数满足哪些特性？
 \16. 有哪些常见的哈希函数？
 \17. 图的遍历[算法]()有哪几种？
 \18. dfs和bfs分别应用于哪种场景？
 \19. 图的最短路径[算法]()有哪些？

 [算法题]()：
 \1. 给定一个二维平面，上面有若干点，求距离最近的两点（答不太上来）
 \2. 给定一个有正有负的序列，找到所有比左边都大比右边都小的数
 答的是双dp，感觉类似合唱队那题和接雨水那题，然后问有没有更好的思路
 往接雨水双指针的[算法]()上引了引，但是时间短压力大没继续想出来

 计网：
 \1. UDP与TCP有什么区别
 \2. UDP的传输内容限制多大（答得256k，应该是512k，混淆了，哭死）
 \3. ping指令是应用在哪个协议下的
 \4. 说说快速重传[算法]()
 \5. 三次握手如果第一次握手没有收到怎么办（没答好，面试官：看来对细节了解不够深啊 哭）
 \6. 套接字了解嘛，有用过这个编写程序吗
 \7. select和epoll的区别

 操作系统：
 \1. 进程通讯有哪些方式
 \2. 同一个进程的线程之间共享哪些，不共享哪些
 \3. 线程同步有哪些方法
 \4. 进程调度有哪些[算法]()
 \5. 内存分页了解吗，置换有哪些[算法]()

 智力题：
 \1. 游戏名重名被占用是怎么检测的
 \2. 给你50个红球，50个白球，两个袋子任意放球，要求我在任意一个袋子里摸球摸出红球的概率最大，怎么放





最小路径[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法)（楼主说了Dijkstra和floyd[算法](https://www.nowcoder.com/jump/super-jump/word?word=算法)）

#### 20220506起床看

[(8条消息) 面试常见海量数据场景题_文杰@的博客-CSDN博客](https://blog.csdn.net/weixin_43988498/article/details/123048982)

[(8条消息) 图论（二）：图的四种最短路径算法_qibofang的博客-CSDN博客_最短路径](https://blog.csdn.net/qibofang/article/details/51594673?spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-2.pc_relevant_paycolumn_v3&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-2.pc_relevant_paycolumn_v3&utm_relevant_index=3)

图论感觉看不完了

哈希

TCPUDP HTTPS

Linux命令，ps

线程安全，
